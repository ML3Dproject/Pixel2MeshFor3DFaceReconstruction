{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/3dproject/lib/python3.7/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functions.base import CheckpointRunner\n",
    "from functions.evaluator import Evaluator\n",
    "from models.classifier import Classifier\n",
    "from models.losses.classifier import CrossEntropyLoss\n",
    "from models.losses.p2m import P2MLoss\n",
    "from models.p2m import P2MModel\n",
    "from utils.average_meter import AverageMeter\n",
    "from utils.mesh import Ellipsoid\n",
    "from utils.tensor import recursive_detach\n",
    "from utils.vis.renderer import MeshRenderer\n",
    "from options import update_options, options, reset_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoid = Ellipsoid(mesh_pos=[0.0, 0.0, -0.8])\n",
    "model = P2MModel(options.model, ellipsoid,\n",
    "                                      options.dataset.camera_f, options.dataset.camera_c,\n",
    "                                      options.dataset.mesh_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import config\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from models.losses.p2m import P2MLoss\n",
    "from utils.mesh import Ellipsoid\n",
    "from utils.average_meter import AverageMeter\n",
    "from functions.evaluator import Evaluator\n",
    "\n",
    "def summarize_model(model):\n",
    "    layers = [(name if len(name) > 0 else 'TOTAL', str(module.__class__.__name__), sum(np.prod(p.shape) for p in module.parameters())) for name, module in model.named_modules()]\n",
    "    layers.append(layers[0])\n",
    "    del layers[0]\n",
    "\n",
    "    columns = [\n",
    "        [\" \", list(map(str, range(len(layers))))],\n",
    "        [\"Name\", [layer[0] for layer in layers]],\n",
    "        [\"Type\", [layer[1] for layer in layers]],\n",
    "        [\"Params\", [layer[2] for layer in layers]],\n",
    "    ]\n",
    "\n",
    "    n_rows = len(columns[0][1])\n",
    "    n_cols = 1 + len(columns)\n",
    "\n",
    "    # Get formatting width of each column\n",
    "    col_widths = []\n",
    "    for c in columns:\n",
    "        col_width = max(len(str(a)) for a in c[1]) if n_rows else 0\n",
    "        col_width = max(col_width, len(c[0]))  # minimum length is header length\n",
    "        col_widths.append(col_width)\n",
    "\n",
    "    # Formatting\n",
    "    s = \"{:<{}}\"\n",
    "    total_width = sum(col_widths) + 3 * n_cols\n",
    "    header = [s.format(c[0], l) for c, l in zip(columns, col_widths)]\n",
    "\n",
    "    summary = \" | \".join(header) + \"\\n\" + \"-\" * total_width\n",
    "    for i in range(n_rows):\n",
    "        line = []\n",
    "        for c, l in zip(columns, col_widths):\n",
    "            line.append(s.format(str(c[1][i]), l))\n",
    "        summary += \"\\n\" + \" | \".join(line)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Name                             | Type              | Params    \n",
      "-----------------------------------------------------------------------------\n",
      "0   | nn_encoder                       | P2MResNet         | 25557032  \n",
      "1   | nn_encoder.conv1                 | Conv2d            | 9408      \n",
      "2   | nn_encoder.bn1                   | BatchNorm2d       | 128       \n",
      "3   | nn_encoder.relu                  | ReLU              | 0         \n",
      "4   | nn_encoder.maxpool               | MaxPool2d         | 0         \n",
      "5   | nn_encoder.layer1                | Sequential        | 215808    \n",
      "6   | nn_encoder.layer1.0              | Bottleneck        | 75008     \n",
      "7   | nn_encoder.layer1.0.conv1        | Conv2d            | 4096      \n",
      "8   | nn_encoder.layer1.0.bn1          | BatchNorm2d       | 128       \n",
      "9   | nn_encoder.layer1.0.conv2        | Conv2d            | 36864     \n",
      "10  | nn_encoder.layer1.0.bn2          | BatchNorm2d       | 128       \n",
      "11  | nn_encoder.layer1.0.conv3        | Conv2d            | 16384     \n",
      "12  | nn_encoder.layer1.0.bn3          | BatchNorm2d       | 512       \n",
      "13  | nn_encoder.layer1.0.relu         | ReLU              | 0         \n",
      "14  | nn_encoder.layer1.0.downsample   | Sequential        | 16896     \n",
      "15  | nn_encoder.layer1.0.downsample.0 | Conv2d            | 16384     \n",
      "16  | nn_encoder.layer1.0.downsample.1 | BatchNorm2d       | 512       \n",
      "17  | nn_encoder.layer1.1              | Bottleneck        | 70400     \n",
      "18  | nn_encoder.layer1.1.conv1        | Conv2d            | 16384     \n",
      "19  | nn_encoder.layer1.1.bn1          | BatchNorm2d       | 128       \n",
      "20  | nn_encoder.layer1.1.conv2        | Conv2d            | 36864     \n",
      "21  | nn_encoder.layer1.1.bn2          | BatchNorm2d       | 128       \n",
      "22  | nn_encoder.layer1.1.conv3        | Conv2d            | 16384     \n",
      "23  | nn_encoder.layer1.1.bn3          | BatchNorm2d       | 512       \n",
      "24  | nn_encoder.layer1.1.relu         | ReLU              | 0         \n",
      "25  | nn_encoder.layer1.2              | Bottleneck        | 70400     \n",
      "26  | nn_encoder.layer1.2.conv1        | Conv2d            | 16384     \n",
      "27  | nn_encoder.layer1.2.bn1          | BatchNorm2d       | 128       \n",
      "28  | nn_encoder.layer1.2.conv2        | Conv2d            | 36864     \n",
      "29  | nn_encoder.layer1.2.bn2          | BatchNorm2d       | 128       \n",
      "30  | nn_encoder.layer1.2.conv3        | Conv2d            | 16384     \n",
      "31  | nn_encoder.layer1.2.bn3          | BatchNorm2d       | 512       \n",
      "32  | nn_encoder.layer1.2.relu         | ReLU              | 0         \n",
      "33  | nn_encoder.layer2                | Sequential        | 1219584   \n",
      "34  | nn_encoder.layer2.0              | Bottleneck        | 379392    \n",
      "35  | nn_encoder.layer2.0.conv1        | Conv2d            | 32768     \n",
      "36  | nn_encoder.layer2.0.bn1          | BatchNorm2d       | 256       \n",
      "37  | nn_encoder.layer2.0.conv2        | Conv2d            | 147456    \n",
      "38  | nn_encoder.layer2.0.bn2          | BatchNorm2d       | 256       \n",
      "39  | nn_encoder.layer2.0.conv3        | Conv2d            | 65536     \n",
      "40  | nn_encoder.layer2.0.bn3          | BatchNorm2d       | 1024      \n",
      "41  | nn_encoder.layer2.0.relu         | ReLU              | 0         \n",
      "42  | nn_encoder.layer2.0.downsample   | Sequential        | 132096    \n",
      "43  | nn_encoder.layer2.0.downsample.0 | Conv2d            | 131072    \n",
      "44  | nn_encoder.layer2.0.downsample.1 | BatchNorm2d       | 1024      \n",
      "45  | nn_encoder.layer2.1              | Bottleneck        | 280064    \n",
      "46  | nn_encoder.layer2.1.conv1        | Conv2d            | 65536     \n",
      "47  | nn_encoder.layer2.1.bn1          | BatchNorm2d       | 256       \n",
      "48  | nn_encoder.layer2.1.conv2        | Conv2d            | 147456    \n",
      "49  | nn_encoder.layer2.1.bn2          | BatchNorm2d       | 256       \n",
      "50  | nn_encoder.layer2.1.conv3        | Conv2d            | 65536     \n",
      "51  | nn_encoder.layer2.1.bn3          | BatchNorm2d       | 1024      \n",
      "52  | nn_encoder.layer2.1.relu         | ReLU              | 0         \n",
      "53  | nn_encoder.layer2.2              | Bottleneck        | 280064    \n",
      "54  | nn_encoder.layer2.2.conv1        | Conv2d            | 65536     \n",
      "55  | nn_encoder.layer2.2.bn1          | BatchNorm2d       | 256       \n",
      "56  | nn_encoder.layer2.2.conv2        | Conv2d            | 147456    \n",
      "57  | nn_encoder.layer2.2.bn2          | BatchNorm2d       | 256       \n",
      "58  | nn_encoder.layer2.2.conv3        | Conv2d            | 65536     \n",
      "59  | nn_encoder.layer2.2.bn3          | BatchNorm2d       | 1024      \n",
      "60  | nn_encoder.layer2.2.relu         | ReLU              | 0         \n",
      "61  | nn_encoder.layer2.3              | Bottleneck        | 280064    \n",
      "62  | nn_encoder.layer2.3.conv1        | Conv2d            | 65536     \n",
      "63  | nn_encoder.layer2.3.bn1          | BatchNorm2d       | 256       \n",
      "64  | nn_encoder.layer2.3.conv2        | Conv2d            | 147456    \n",
      "65  | nn_encoder.layer2.3.bn2          | BatchNorm2d       | 256       \n",
      "66  | nn_encoder.layer2.3.conv3        | Conv2d            | 65536     \n",
      "67  | nn_encoder.layer2.3.bn3          | BatchNorm2d       | 1024      \n",
      "68  | nn_encoder.layer2.3.relu         | ReLU              | 0         \n",
      "69  | nn_encoder.layer3                | Sequential        | 7098368   \n",
      "70  | nn_encoder.layer3.0              | Bottleneck        | 1512448   \n",
      "71  | nn_encoder.layer3.0.conv1        | Conv2d            | 131072    \n",
      "72  | nn_encoder.layer3.0.bn1          | BatchNorm2d       | 512       \n",
      "73  | nn_encoder.layer3.0.conv2        | Conv2d            | 589824    \n",
      "74  | nn_encoder.layer3.0.bn2          | BatchNorm2d       | 512       \n",
      "75  | nn_encoder.layer3.0.conv3        | Conv2d            | 262144    \n",
      "76  | nn_encoder.layer3.0.bn3          | BatchNorm2d       | 2048      \n",
      "77  | nn_encoder.layer3.0.relu         | ReLU              | 0         \n",
      "78  | nn_encoder.layer3.0.downsample   | Sequential        | 526336    \n",
      "79  | nn_encoder.layer3.0.downsample.0 | Conv2d            | 524288    \n",
      "80  | nn_encoder.layer3.0.downsample.1 | BatchNorm2d       | 2048      \n",
      "81  | nn_encoder.layer3.1              | Bottleneck        | 1117184   \n",
      "82  | nn_encoder.layer3.1.conv1        | Conv2d            | 262144    \n",
      "83  | nn_encoder.layer3.1.bn1          | BatchNorm2d       | 512       \n",
      "84  | nn_encoder.layer3.1.conv2        | Conv2d            | 589824    \n",
      "85  | nn_encoder.layer3.1.bn2          | BatchNorm2d       | 512       \n",
      "86  | nn_encoder.layer3.1.conv3        | Conv2d            | 262144    \n",
      "87  | nn_encoder.layer3.1.bn3          | BatchNorm2d       | 2048      \n",
      "88  | nn_encoder.layer3.1.relu         | ReLU              | 0         \n",
      "89  | nn_encoder.layer3.2              | Bottleneck        | 1117184   \n",
      "90  | nn_encoder.layer3.2.conv1        | Conv2d            | 262144    \n",
      "91  | nn_encoder.layer3.2.bn1          | BatchNorm2d       | 512       \n",
      "92  | nn_encoder.layer3.2.conv2        | Conv2d            | 589824    \n",
      "93  | nn_encoder.layer3.2.bn2          | BatchNorm2d       | 512       \n",
      "94  | nn_encoder.layer3.2.conv3        | Conv2d            | 262144    \n",
      "95  | nn_encoder.layer3.2.bn3          | BatchNorm2d       | 2048      \n",
      "96  | nn_encoder.layer3.2.relu         | ReLU              | 0         \n",
      "97  | nn_encoder.layer3.3              | Bottleneck        | 1117184   \n",
      "98  | nn_encoder.layer3.3.conv1        | Conv2d            | 262144    \n",
      "99  | nn_encoder.layer3.3.bn1          | BatchNorm2d       | 512       \n",
      "100 | nn_encoder.layer3.3.conv2        | Conv2d            | 589824    \n",
      "101 | nn_encoder.layer3.3.bn2          | BatchNorm2d       | 512       \n",
      "102 | nn_encoder.layer3.3.conv3        | Conv2d            | 262144    \n",
      "103 | nn_encoder.layer3.3.bn3          | BatchNorm2d       | 2048      \n",
      "104 | nn_encoder.layer3.3.relu         | ReLU              | 0         \n",
      "105 | nn_encoder.layer3.4              | Bottleneck        | 1117184   \n",
      "106 | nn_encoder.layer3.4.conv1        | Conv2d            | 262144    \n",
      "107 | nn_encoder.layer3.4.bn1          | BatchNorm2d       | 512       \n",
      "108 | nn_encoder.layer3.4.conv2        | Conv2d            | 589824    \n",
      "109 | nn_encoder.layer3.4.bn2          | BatchNorm2d       | 512       \n",
      "110 | nn_encoder.layer3.4.conv3        | Conv2d            | 262144    \n",
      "111 | nn_encoder.layer3.4.bn3          | BatchNorm2d       | 2048      \n",
      "112 | nn_encoder.layer3.4.relu         | ReLU              | 0         \n",
      "113 | nn_encoder.layer3.5              | Bottleneck        | 1117184   \n",
      "114 | nn_encoder.layer3.5.conv1        | Conv2d            | 262144    \n",
      "115 | nn_encoder.layer3.5.bn1          | BatchNorm2d       | 512       \n",
      "116 | nn_encoder.layer3.5.conv2        | Conv2d            | 589824    \n",
      "117 | nn_encoder.layer3.5.bn2          | BatchNorm2d       | 512       \n",
      "118 | nn_encoder.layer3.5.conv3        | Conv2d            | 262144    \n",
      "119 | nn_encoder.layer3.5.bn3          | BatchNorm2d       | 2048      \n",
      "120 | nn_encoder.layer3.5.relu         | ReLU              | 0         \n",
      "121 | nn_encoder.layer4                | Sequential        | 14964736  \n",
      "122 | nn_encoder.layer4.0              | Bottleneck        | 6039552   \n",
      "123 | nn_encoder.layer4.0.conv1        | Conv2d            | 524288    \n",
      "124 | nn_encoder.layer4.0.bn1          | BatchNorm2d       | 1024      \n",
      "125 | nn_encoder.layer4.0.conv2        | Conv2d            | 2359296   \n",
      "126 | nn_encoder.layer4.0.bn2          | BatchNorm2d       | 1024      \n",
      "127 | nn_encoder.layer4.0.conv3        | Conv2d            | 1048576   \n",
      "128 | nn_encoder.layer4.0.bn3          | BatchNorm2d       | 4096      \n",
      "129 | nn_encoder.layer4.0.relu         | ReLU              | 0         \n",
      "130 | nn_encoder.layer4.0.downsample   | Sequential        | 2101248   \n",
      "131 | nn_encoder.layer4.0.downsample.0 | Conv2d            | 2097152   \n",
      "132 | nn_encoder.layer4.0.downsample.1 | BatchNorm2d       | 4096      \n",
      "133 | nn_encoder.layer4.1              | Bottleneck        | 4462592   \n",
      "134 | nn_encoder.layer4.1.conv1        | Conv2d            | 1048576   \n",
      "135 | nn_encoder.layer4.1.bn1          | BatchNorm2d       | 1024      \n",
      "136 | nn_encoder.layer4.1.conv2        | Conv2d            | 2359296   \n",
      "137 | nn_encoder.layer4.1.bn2          | BatchNorm2d       | 1024      \n",
      "138 | nn_encoder.layer4.1.conv3        | Conv2d            | 1048576   \n",
      "139 | nn_encoder.layer4.1.bn3          | BatchNorm2d       | 4096      \n",
      "140 | nn_encoder.layer4.1.relu         | ReLU              | 0         \n",
      "141 | nn_encoder.layer4.2              | Bottleneck        | 4462592   \n",
      "142 | nn_encoder.layer4.2.conv1        | Conv2d            | 1048576   \n",
      "143 | nn_encoder.layer4.2.bn1          | BatchNorm2d       | 1024      \n",
      "144 | nn_encoder.layer4.2.conv2        | Conv2d            | 2359296   \n",
      "145 | nn_encoder.layer4.2.bn2          | BatchNorm2d       | 1024      \n",
      "146 | nn_encoder.layer4.2.conv3        | Conv2d            | 1048576   \n",
      "147 | nn_encoder.layer4.2.bn3          | BatchNorm2d       | 4096      \n",
      "148 | nn_encoder.layer4.2.relu         | ReLU              | 0         \n",
      "149 | nn_encoder.avgpool               | AdaptiveAvgPool2d | 0         \n",
      "150 | nn_encoder.fc                    | Linear            | 2049000   \n",
      "151 | gcns                             | ModuleList        | 1461096465\n",
      "152 | gcns.0                           | GBottleneck       | 2704803   \n",
      "153 | gcns.0.blocks                    | Sequential        | 1179072   \n",
      "154 | gcns.0.blocks.0                  | GResBlock         | 196512    \n",
      "155 | gcns.0.blocks.0.conv1            | GConv             | 98256     \n",
      "156 | gcns.0.blocks.0.conv2            | GConv             | 98256     \n",
      "157 | gcns.0.blocks.1                  | GResBlock         | 196512    \n",
      "158 | gcns.0.blocks.1.conv1            | GConv             | 98256     \n",
      "159 | gcns.0.blocks.1.conv2            | GConv             | 98256     \n",
      "160 | gcns.0.blocks.2                  | GResBlock         | 196512    \n",
      "161 | gcns.0.blocks.2.conv1            | GConv             | 98256     \n",
      "162 | gcns.0.blocks.2.conv2            | GConv             | 98256     \n",
      "163 | gcns.0.blocks.3                  | GResBlock         | 196512    \n",
      "164 | gcns.0.blocks.3.conv1            | GConv             | 98256     \n",
      "165 | gcns.0.blocks.3.conv2            | GConv             | 98256     \n",
      "166 | gcns.0.blocks.4                  | GResBlock         | 196512    \n",
      "167 | gcns.0.blocks.4.conv1            | GConv             | 98256     \n",
      "168 | gcns.0.blocks.4.conv2            | GConv             | 98256     \n",
      "169 | gcns.0.blocks.5                  | GResBlock         | 196512    \n",
      "170 | gcns.0.blocks.5.conv1            | GConv             | 98256     \n",
      "171 | gcns.0.blocks.5.conv2            | GConv             | 98256     \n",
      "172 | gcns.0.conv1                     | GConv             | 1500240   \n",
      "173 | gcns.0.conv2                     | GConv             | 25491     \n",
      "174 | gcns.1                           | GBottleneck       | 7784763   \n",
      "175 | gcns.1.blocks                    | Sequential        | 5470128   \n",
      "176 | gcns.1.blocks.0                  | GResBlock         | 911688    \n",
      "177 | gcns.1.blocks.0.conv1            | GConv             | 455844    \n",
      "178 | gcns.1.blocks.0.conv2            | GConv             | 455844    \n",
      "179 | gcns.1.blocks.1                  | GResBlock         | 911688    \n",
      "180 | gcns.1.blocks.1.conv1            | GConv             | 455844    \n",
      "181 | gcns.1.blocks.1.conv2            | GConv             | 455844    \n",
      "182 | gcns.1.blocks.2                  | GResBlock         | 911688    \n",
      "183 | gcns.1.blocks.2.conv1            | GConv             | 455844    \n",
      "184 | gcns.1.blocks.2.conv2            | GConv             | 455844    \n",
      "185 | gcns.1.blocks.3                  | GResBlock         | 911688    \n",
      "186 | gcns.1.blocks.3.conv1            | GConv             | 455844    \n",
      "187 | gcns.1.blocks.3.conv2            | GConv             | 455844    \n",
      "188 | gcns.1.blocks.4                  | GResBlock         | 911688    \n",
      "189 | gcns.1.blocks.4.conv1            | GConv             | 455844    \n",
      "190 | gcns.1.blocks.4.conv2            | GConv             | 455844    \n",
      "191 | gcns.1.blocks.5                  | GResBlock         | 911688    \n",
      "192 | gcns.1.blocks.5.conv1            | GConv             | 455844    \n",
      "193 | gcns.1.blocks.5.conv2            | GConv             | 455844    \n",
      "194 | gcns.1.conv1                     | GConv             | 1931556   \n",
      "195 | gcns.1.conv2                     | GConv             | 383079    \n",
      "196 | gcns.2                           | GBottleneck       | 87574011  \n",
      "197 | gcns.2.blocks                    | Sequential        | 73860912  \n",
      "198 | gcns.2.blocks.0                  | GResBlock         | 12310152  \n",
      "199 | gcns.2.blocks.0.conv1            | GConv             | 6155076   \n",
      "200 | gcns.2.blocks.0.conv2            | GConv             | 6155076   \n",
      "201 | gcns.2.blocks.1                  | GResBlock         | 12310152  \n",
      "202 | gcns.2.blocks.1.conv1            | GConv             | 6155076   \n",
      "203 | gcns.2.blocks.1.conv2            | GConv             | 6155076   \n",
      "204 | gcns.2.blocks.2                  | GResBlock         | 12310152  \n",
      "205 | gcns.2.blocks.2.conv1            | GConv             | 6155076   \n",
      "206 | gcns.2.blocks.2.conv2            | GConv             | 6155076   \n",
      "207 | gcns.2.blocks.3                  | GResBlock         | 12310152  \n",
      "208 | gcns.2.blocks.3.conv1            | GConv             | 6155076   \n",
      "209 | gcns.2.blocks.3.conv2            | GConv             | 6155076   \n",
      "210 | gcns.2.blocks.4                  | GResBlock         | 12310152  \n",
      "211 | gcns.2.blocks.4.conv1            | GConv             | 6155076   \n",
      "212 | gcns.2.blocks.4.conv2            | GConv             | 6155076   \n",
      "213 | gcns.2.blocks.5                  | GResBlock         | 12310152  \n",
      "214 | gcns.2.blocks.5.conv1            | GConv             | 6155076   \n",
      "215 | gcns.2.blocks.5.conv2            | GConv             | 6155076   \n",
      "216 | gcns.2.conv1                     | GConv             | 7630788   \n",
      "217 | gcns.2.conv2                     | GConv             | 6082311   \n",
      "218 | gcns.3                           | GBottleneck       | 1363032888\n",
      "219 | gcns.3.blocks                    | Sequential        | 1167049008\n",
      "220 | gcns.3.blocks.0                  | GResBlock         | 194508168 \n",
      "221 | gcns.3.blocks.0.conv1            | GConv             | 97254084  \n",
      "222 | gcns.3.blocks.0.conv2            | GConv             | 97254084  \n",
      "223 | gcns.3.blocks.1                  | GResBlock         | 194508168 \n",
      "224 | gcns.3.blocks.1.conv1            | GConv             | 97254084  \n",
      "225 | gcns.3.blocks.1.conv2            | GConv             | 97254084  \n",
      "226 | gcns.3.blocks.2                  | GResBlock         | 194508168 \n",
      "227 | gcns.3.blocks.2.conv1            | GConv             | 97254084  \n",
      "228 | gcns.3.blocks.2.conv2            | GConv             | 97254084  \n",
      "229 | gcns.3.blocks.3                  | GResBlock         | 194508168 \n",
      "230 | gcns.3.blocks.3.conv1            | GConv             | 97254084  \n",
      "231 | gcns.3.blocks.3.conv2            | GConv             | 97254084  \n",
      "232 | gcns.3.blocks.4                  | GResBlock         | 194508168 \n",
      "233 | gcns.3.blocks.4.conv1            | GConv             | 97254084  \n",
      "234 | gcns.3.blocks.4.conv2            | GConv             | 97254084  \n",
      "235 | gcns.3.blocks.5                  | GResBlock         | 194508168 \n",
      "236 | gcns.3.blocks.5.conv1            | GConv             | 97254084  \n",
      "237 | gcns.3.blocks.5.conv2            | GConv             | 97254084  \n",
      "238 | gcns.3.conv1                     | GConv             | 98729796  \n",
      "239 | gcns.3.conv2                     | GConv             | 97254084  \n",
      "240 | unpooling                        | ModuleList        | 0         \n",
      "241 | unpooling.0                      | GUnpooling        | 0         \n",
      "242 | unpooling.1                      | GUnpooling        | 0         \n",
      "243 | unpooling.2                      | GUnpooling        | 0         \n",
      "244 | projection                       | GProjection       | 0         \n",
      "245 | gconv                            | GConv             | 97181319  \n",
      "246 | TOTAL                            | P2MModel          | 1583835284\n"
     ]
    }
   ],
   "source": [
    "print(summarize_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['init_pts', 'nn_encoder.conv1.weight', 'nn_encoder.bn1.weight', 'nn_encoder.bn1.bias', 'nn_encoder.bn1.running_mean', 'nn_encoder.bn1.running_var', 'nn_encoder.bn1.num_batches_tracked', 'nn_encoder.layer1.0.conv1.weight', 'nn_encoder.layer1.0.bn1.weight', 'nn_encoder.layer1.0.bn1.bias', 'nn_encoder.layer1.0.bn1.running_mean', 'nn_encoder.layer1.0.bn1.running_var', 'nn_encoder.layer1.0.bn1.num_batches_tracked', 'nn_encoder.layer1.0.conv2.weight', 'nn_encoder.layer1.0.bn2.weight', 'nn_encoder.layer1.0.bn2.bias', 'nn_encoder.layer1.0.bn2.running_mean', 'nn_encoder.layer1.0.bn2.running_var', 'nn_encoder.layer1.0.bn2.num_batches_tracked', 'nn_encoder.layer1.0.conv3.weight', 'nn_encoder.layer1.0.bn3.weight', 'nn_encoder.layer1.0.bn3.bias', 'nn_encoder.layer1.0.bn3.running_mean', 'nn_encoder.layer1.0.bn3.running_var', 'nn_encoder.layer1.0.bn3.num_batches_tracked', 'nn_encoder.layer1.0.downsample.0.weight', 'nn_encoder.layer1.0.downsample.1.weight', 'nn_encoder.layer1.0.downsample.1.bias', 'nn_encoder.layer1.0.downsample.1.running_mean', 'nn_encoder.layer1.0.downsample.1.running_var', 'nn_encoder.layer1.0.downsample.1.num_batches_tracked', 'nn_encoder.layer1.1.conv1.weight', 'nn_encoder.layer1.1.bn1.weight', 'nn_encoder.layer1.1.bn1.bias', 'nn_encoder.layer1.1.bn1.running_mean', 'nn_encoder.layer1.1.bn1.running_var', 'nn_encoder.layer1.1.bn1.num_batches_tracked', 'nn_encoder.layer1.1.conv2.weight', 'nn_encoder.layer1.1.bn2.weight', 'nn_encoder.layer1.1.bn2.bias', 'nn_encoder.layer1.1.bn2.running_mean', 'nn_encoder.layer1.1.bn2.running_var', 'nn_encoder.layer1.1.bn2.num_batches_tracked', 'nn_encoder.layer1.1.conv3.weight', 'nn_encoder.layer1.1.bn3.weight', 'nn_encoder.layer1.1.bn3.bias', 'nn_encoder.layer1.1.bn3.running_mean', 'nn_encoder.layer1.1.bn3.running_var', 'nn_encoder.layer1.1.bn3.num_batches_tracked', 'nn_encoder.layer1.2.conv1.weight', 'nn_encoder.layer1.2.bn1.weight', 'nn_encoder.layer1.2.bn1.bias', 'nn_encoder.layer1.2.bn1.running_mean', 'nn_encoder.layer1.2.bn1.running_var', 'nn_encoder.layer1.2.bn1.num_batches_tracked', 'nn_encoder.layer1.2.conv2.weight', 'nn_encoder.layer1.2.bn2.weight', 'nn_encoder.layer1.2.bn2.bias', 'nn_encoder.layer1.2.bn2.running_mean', 'nn_encoder.layer1.2.bn2.running_var', 'nn_encoder.layer1.2.bn2.num_batches_tracked', 'nn_encoder.layer1.2.conv3.weight', 'nn_encoder.layer1.2.bn3.weight', 'nn_encoder.layer1.2.bn3.bias', 'nn_encoder.layer1.2.bn3.running_mean', 'nn_encoder.layer1.2.bn3.running_var', 'nn_encoder.layer1.2.bn3.num_batches_tracked', 'nn_encoder.layer2.0.conv1.weight', 'nn_encoder.layer2.0.bn1.weight', 'nn_encoder.layer2.0.bn1.bias', 'nn_encoder.layer2.0.bn1.running_mean', 'nn_encoder.layer2.0.bn1.running_var', 'nn_encoder.layer2.0.bn1.num_batches_tracked', 'nn_encoder.layer2.0.conv2.weight', 'nn_encoder.layer2.0.bn2.weight', 'nn_encoder.layer2.0.bn2.bias', 'nn_encoder.layer2.0.bn2.running_mean', 'nn_encoder.layer2.0.bn2.running_var', 'nn_encoder.layer2.0.bn2.num_batches_tracked', 'nn_encoder.layer2.0.conv3.weight', 'nn_encoder.layer2.0.bn3.weight', 'nn_encoder.layer2.0.bn3.bias', 'nn_encoder.layer2.0.bn3.running_mean', 'nn_encoder.layer2.0.bn3.running_var', 'nn_encoder.layer2.0.bn3.num_batches_tracked', 'nn_encoder.layer2.0.downsample.0.weight', 'nn_encoder.layer2.0.downsample.1.weight', 'nn_encoder.layer2.0.downsample.1.bias', 'nn_encoder.layer2.0.downsample.1.running_mean', 'nn_encoder.layer2.0.downsample.1.running_var', 'nn_encoder.layer2.0.downsample.1.num_batches_tracked', 'nn_encoder.layer2.1.conv1.weight', 'nn_encoder.layer2.1.bn1.weight', 'nn_encoder.layer2.1.bn1.bias', 'nn_encoder.layer2.1.bn1.running_mean', 'nn_encoder.layer2.1.bn1.running_var', 'nn_encoder.layer2.1.bn1.num_batches_tracked', 'nn_encoder.layer2.1.conv2.weight', 'nn_encoder.layer2.1.bn2.weight', 'nn_encoder.layer2.1.bn2.bias', 'nn_encoder.layer2.1.bn2.running_mean', 'nn_encoder.layer2.1.bn2.running_var', 'nn_encoder.layer2.1.bn2.num_batches_tracked', 'nn_encoder.layer2.1.conv3.weight', 'nn_encoder.layer2.1.bn3.weight', 'nn_encoder.layer2.1.bn3.bias', 'nn_encoder.layer2.1.bn3.running_mean', 'nn_encoder.layer2.1.bn3.running_var', 'nn_encoder.layer2.1.bn3.num_batches_tracked', 'nn_encoder.layer2.2.conv1.weight', 'nn_encoder.layer2.2.bn1.weight', 'nn_encoder.layer2.2.bn1.bias', 'nn_encoder.layer2.2.bn1.running_mean', 'nn_encoder.layer2.2.bn1.running_var', 'nn_encoder.layer2.2.bn1.num_batches_tracked', 'nn_encoder.layer2.2.conv2.weight', 'nn_encoder.layer2.2.bn2.weight', 'nn_encoder.layer2.2.bn2.bias', 'nn_encoder.layer2.2.bn2.running_mean', 'nn_encoder.layer2.2.bn2.running_var', 'nn_encoder.layer2.2.bn2.num_batches_tracked', 'nn_encoder.layer2.2.conv3.weight', 'nn_encoder.layer2.2.bn3.weight', 'nn_encoder.layer2.2.bn3.bias', 'nn_encoder.layer2.2.bn3.running_mean', 'nn_encoder.layer2.2.bn3.running_var', 'nn_encoder.layer2.2.bn3.num_batches_tracked', 'nn_encoder.layer2.3.conv1.weight', 'nn_encoder.layer2.3.bn1.weight', 'nn_encoder.layer2.3.bn1.bias', 'nn_encoder.layer2.3.bn1.running_mean', 'nn_encoder.layer2.3.bn1.running_var', 'nn_encoder.layer2.3.bn1.num_batches_tracked', 'nn_encoder.layer2.3.conv2.weight', 'nn_encoder.layer2.3.bn2.weight', 'nn_encoder.layer2.3.bn2.bias', 'nn_encoder.layer2.3.bn2.running_mean', 'nn_encoder.layer2.3.bn2.running_var', 'nn_encoder.layer2.3.bn2.num_batches_tracked', 'nn_encoder.layer2.3.conv3.weight', 'nn_encoder.layer2.3.bn3.weight', 'nn_encoder.layer2.3.bn3.bias', 'nn_encoder.layer2.3.bn3.running_mean', 'nn_encoder.layer2.3.bn3.running_var', 'nn_encoder.layer2.3.bn3.num_batches_tracked', 'nn_encoder.layer3.0.conv1.weight', 'nn_encoder.layer3.0.bn1.weight', 'nn_encoder.layer3.0.bn1.bias', 'nn_encoder.layer3.0.bn1.running_mean', 'nn_encoder.layer3.0.bn1.running_var', 'nn_encoder.layer3.0.bn1.num_batches_tracked', 'nn_encoder.layer3.0.conv2.weight', 'nn_encoder.layer3.0.bn2.weight', 'nn_encoder.layer3.0.bn2.bias', 'nn_encoder.layer3.0.bn2.running_mean', 'nn_encoder.layer3.0.bn2.running_var', 'nn_encoder.layer3.0.bn2.num_batches_tracked', 'nn_encoder.layer3.0.conv3.weight', 'nn_encoder.layer3.0.bn3.weight', 'nn_encoder.layer3.0.bn3.bias', 'nn_encoder.layer3.0.bn3.running_mean', 'nn_encoder.layer3.0.bn3.running_var', 'nn_encoder.layer3.0.bn3.num_batches_tracked', 'nn_encoder.layer3.0.downsample.0.weight', 'nn_encoder.layer3.0.downsample.1.weight', 'nn_encoder.layer3.0.downsample.1.bias', 'nn_encoder.layer3.0.downsample.1.running_mean', 'nn_encoder.layer3.0.downsample.1.running_var', 'nn_encoder.layer3.0.downsample.1.num_batches_tracked', 'nn_encoder.layer3.1.conv1.weight', 'nn_encoder.layer3.1.bn1.weight', 'nn_encoder.layer3.1.bn1.bias', 'nn_encoder.layer3.1.bn1.running_mean', 'nn_encoder.layer3.1.bn1.running_var', 'nn_encoder.layer3.1.bn1.num_batches_tracked', 'nn_encoder.layer3.1.conv2.weight', 'nn_encoder.layer3.1.bn2.weight', 'nn_encoder.layer3.1.bn2.bias', 'nn_encoder.layer3.1.bn2.running_mean', 'nn_encoder.layer3.1.bn2.running_var', 'nn_encoder.layer3.1.bn2.num_batches_tracked', 'nn_encoder.layer3.1.conv3.weight', 'nn_encoder.layer3.1.bn3.weight', 'nn_encoder.layer3.1.bn3.bias', 'nn_encoder.layer3.1.bn3.running_mean', 'nn_encoder.layer3.1.bn3.running_var', 'nn_encoder.layer3.1.bn3.num_batches_tracked', 'nn_encoder.layer3.2.conv1.weight', 'nn_encoder.layer3.2.bn1.weight', 'nn_encoder.layer3.2.bn1.bias', 'nn_encoder.layer3.2.bn1.running_mean', 'nn_encoder.layer3.2.bn1.running_var', 'nn_encoder.layer3.2.bn1.num_batches_tracked', 'nn_encoder.layer3.2.conv2.weight', 'nn_encoder.layer3.2.bn2.weight', 'nn_encoder.layer3.2.bn2.bias', 'nn_encoder.layer3.2.bn2.running_mean', 'nn_encoder.layer3.2.bn2.running_var', 'nn_encoder.layer3.2.bn2.num_batches_tracked', 'nn_encoder.layer3.2.conv3.weight', 'nn_encoder.layer3.2.bn3.weight', 'nn_encoder.layer3.2.bn3.bias', 'nn_encoder.layer3.2.bn3.running_mean', 'nn_encoder.layer3.2.bn3.running_var', 'nn_encoder.layer3.2.bn3.num_batches_tracked', 'nn_encoder.layer3.3.conv1.weight', 'nn_encoder.layer3.3.bn1.weight', 'nn_encoder.layer3.3.bn1.bias', 'nn_encoder.layer3.3.bn1.running_mean', 'nn_encoder.layer3.3.bn1.running_var', 'nn_encoder.layer3.3.bn1.num_batches_tracked', 'nn_encoder.layer3.3.conv2.weight', 'nn_encoder.layer3.3.bn2.weight', 'nn_encoder.layer3.3.bn2.bias', 'nn_encoder.layer3.3.bn2.running_mean', 'nn_encoder.layer3.3.bn2.running_var', 'nn_encoder.layer3.3.bn2.num_batches_tracked', 'nn_encoder.layer3.3.conv3.weight', 'nn_encoder.layer3.3.bn3.weight', 'nn_encoder.layer3.3.bn3.bias', 'nn_encoder.layer3.3.bn3.running_mean', 'nn_encoder.layer3.3.bn3.running_var', 'nn_encoder.layer3.3.bn3.num_batches_tracked', 'nn_encoder.layer3.4.conv1.weight', 'nn_encoder.layer3.4.bn1.weight', 'nn_encoder.layer3.4.bn1.bias', 'nn_encoder.layer3.4.bn1.running_mean', 'nn_encoder.layer3.4.bn1.running_var', 'nn_encoder.layer3.4.bn1.num_batches_tracked', 'nn_encoder.layer3.4.conv2.weight', 'nn_encoder.layer3.4.bn2.weight', 'nn_encoder.layer3.4.bn2.bias', 'nn_encoder.layer3.4.bn2.running_mean', 'nn_encoder.layer3.4.bn2.running_var', 'nn_encoder.layer3.4.bn2.num_batches_tracked', 'nn_encoder.layer3.4.conv3.weight', 'nn_encoder.layer3.4.bn3.weight', 'nn_encoder.layer3.4.bn3.bias', 'nn_encoder.layer3.4.bn3.running_mean', 'nn_encoder.layer3.4.bn3.running_var', 'nn_encoder.layer3.4.bn3.num_batches_tracked', 'nn_encoder.layer3.5.conv1.weight', 'nn_encoder.layer3.5.bn1.weight', 'nn_encoder.layer3.5.bn1.bias', 'nn_encoder.layer3.5.bn1.running_mean', 'nn_encoder.layer3.5.bn1.running_var', 'nn_encoder.layer3.5.bn1.num_batches_tracked', 'nn_encoder.layer3.5.conv2.weight', 'nn_encoder.layer3.5.bn2.weight', 'nn_encoder.layer3.5.bn2.bias', 'nn_encoder.layer3.5.bn2.running_mean', 'nn_encoder.layer3.5.bn2.running_var', 'nn_encoder.layer3.5.bn2.num_batches_tracked', 'nn_encoder.layer3.5.conv3.weight', 'nn_encoder.layer3.5.bn3.weight', 'nn_encoder.layer3.5.bn3.bias', 'nn_encoder.layer3.5.bn3.running_mean', 'nn_encoder.layer3.5.bn3.running_var', 'nn_encoder.layer3.5.bn3.num_batches_tracked', 'nn_encoder.layer4.0.conv1.weight', 'nn_encoder.layer4.0.bn1.weight', 'nn_encoder.layer4.0.bn1.bias', 'nn_encoder.layer4.0.bn1.running_mean', 'nn_encoder.layer4.0.bn1.running_var', 'nn_encoder.layer4.0.bn1.num_batches_tracked', 'nn_encoder.layer4.0.conv2.weight', 'nn_encoder.layer4.0.bn2.weight', 'nn_encoder.layer4.0.bn2.bias', 'nn_encoder.layer4.0.bn2.running_mean', 'nn_encoder.layer4.0.bn2.running_var', 'nn_encoder.layer4.0.bn2.num_batches_tracked', 'nn_encoder.layer4.0.conv3.weight', 'nn_encoder.layer4.0.bn3.weight', 'nn_encoder.layer4.0.bn3.bias', 'nn_encoder.layer4.0.bn3.running_mean', 'nn_encoder.layer4.0.bn3.running_var', 'nn_encoder.layer4.0.bn3.num_batches_tracked', 'nn_encoder.layer4.0.downsample.0.weight', 'nn_encoder.layer4.0.downsample.1.weight', 'nn_encoder.layer4.0.downsample.1.bias', 'nn_encoder.layer4.0.downsample.1.running_mean', 'nn_encoder.layer4.0.downsample.1.running_var', 'nn_encoder.layer4.0.downsample.1.num_batches_tracked', 'nn_encoder.layer4.1.conv1.weight', 'nn_encoder.layer4.1.bn1.weight', 'nn_encoder.layer4.1.bn1.bias', 'nn_encoder.layer4.1.bn1.running_mean', 'nn_encoder.layer4.1.bn1.running_var', 'nn_encoder.layer4.1.bn1.num_batches_tracked', 'nn_encoder.layer4.1.conv2.weight', 'nn_encoder.layer4.1.bn2.weight', 'nn_encoder.layer4.1.bn2.bias', 'nn_encoder.layer4.1.bn2.running_mean', 'nn_encoder.layer4.1.bn2.running_var', 'nn_encoder.layer4.1.bn2.num_batches_tracked', 'nn_encoder.layer4.1.conv3.weight', 'nn_encoder.layer4.1.bn3.weight', 'nn_encoder.layer4.1.bn3.bias', 'nn_encoder.layer4.1.bn3.running_mean', 'nn_encoder.layer4.1.bn3.running_var', 'nn_encoder.layer4.1.bn3.num_batches_tracked', 'nn_encoder.layer4.2.conv1.weight', 'nn_encoder.layer4.2.bn1.weight', 'nn_encoder.layer4.2.bn1.bias', 'nn_encoder.layer4.2.bn1.running_mean', 'nn_encoder.layer4.2.bn1.running_var', 'nn_encoder.layer4.2.bn1.num_batches_tracked', 'nn_encoder.layer4.2.conv2.weight', 'nn_encoder.layer4.2.bn2.weight', 'nn_encoder.layer4.2.bn2.bias', 'nn_encoder.layer4.2.bn2.running_mean', 'nn_encoder.layer4.2.bn2.running_var', 'nn_encoder.layer4.2.bn2.num_batches_tracked', 'nn_encoder.layer4.2.conv3.weight', 'nn_encoder.layer4.2.bn3.weight', 'nn_encoder.layer4.2.bn3.bias', 'nn_encoder.layer4.2.bn3.running_mean', 'nn_encoder.layer4.2.bn3.running_var', 'nn_encoder.layer4.2.bn3.num_batches_tracked', 'nn_encoder.fc.weight', 'nn_encoder.fc.bias', 'gcns.0.blocks.0.conv1.weight', 'gcns.0.blocks.0.conv1.loop_weight', 'gcns.0.blocks.0.conv1.bias', 'gcns.0.blocks.0.conv2.weight', 'gcns.0.blocks.0.conv2.loop_weight', 'gcns.0.blocks.0.conv2.bias', 'gcns.0.blocks.1.conv1.weight', 'gcns.0.blocks.1.conv1.loop_weight', 'gcns.0.blocks.1.conv1.bias', 'gcns.0.blocks.1.conv2.weight', 'gcns.0.blocks.1.conv2.loop_weight', 'gcns.0.blocks.1.conv2.bias', 'gcns.0.blocks.2.conv1.weight', 'gcns.0.blocks.2.conv1.loop_weight', 'gcns.0.blocks.2.conv1.bias', 'gcns.0.blocks.2.conv2.weight', 'gcns.0.blocks.2.conv2.loop_weight', 'gcns.0.blocks.2.conv2.bias', 'gcns.0.blocks.3.conv1.weight', 'gcns.0.blocks.3.conv1.loop_weight', 'gcns.0.blocks.3.conv1.bias', 'gcns.0.blocks.3.conv2.weight', 'gcns.0.blocks.3.conv2.loop_weight', 'gcns.0.blocks.3.conv2.bias', 'gcns.0.blocks.4.conv1.weight', 'gcns.0.blocks.4.conv1.loop_weight', 'gcns.0.blocks.4.conv1.bias', 'gcns.0.blocks.4.conv2.weight', 'gcns.0.blocks.4.conv2.loop_weight', 'gcns.0.blocks.4.conv2.bias', 'gcns.0.blocks.5.conv1.weight', 'gcns.0.blocks.5.conv1.loop_weight', 'gcns.0.blocks.5.conv1.bias', 'gcns.0.blocks.5.conv2.weight', 'gcns.0.blocks.5.conv2.loop_weight', 'gcns.0.blocks.5.conv2.bias', 'gcns.0.conv1.weight', 'gcns.0.conv1.loop_weight', 'gcns.0.conv1.bias', 'gcns.0.conv2.weight', 'gcns.0.conv2.loop_weight', 'gcns.0.conv2.bias', 'gcns.1.blocks.0.conv1.weight', 'gcns.1.blocks.0.conv1.loop_weight', 'gcns.1.blocks.0.conv1.bias', 'gcns.1.blocks.0.conv2.weight', 'gcns.1.blocks.0.conv2.loop_weight', 'gcns.1.blocks.0.conv2.bias', 'gcns.1.blocks.1.conv1.weight', 'gcns.1.blocks.1.conv1.loop_weight', 'gcns.1.blocks.1.conv1.bias', 'gcns.1.blocks.1.conv2.weight', 'gcns.1.blocks.1.conv2.loop_weight', 'gcns.1.blocks.1.conv2.bias', 'gcns.1.blocks.2.conv1.weight', 'gcns.1.blocks.2.conv1.loop_weight', 'gcns.1.blocks.2.conv1.bias', 'gcns.1.blocks.2.conv2.weight', 'gcns.1.blocks.2.conv2.loop_weight', 'gcns.1.blocks.2.conv2.bias', 'gcns.1.blocks.3.conv1.weight', 'gcns.1.blocks.3.conv1.loop_weight', 'gcns.1.blocks.3.conv1.bias', 'gcns.1.blocks.3.conv2.weight', 'gcns.1.blocks.3.conv2.loop_weight', 'gcns.1.blocks.3.conv2.bias', 'gcns.1.blocks.4.conv1.weight', 'gcns.1.blocks.4.conv1.loop_weight', 'gcns.1.blocks.4.conv1.bias', 'gcns.1.blocks.4.conv2.weight', 'gcns.1.blocks.4.conv2.loop_weight', 'gcns.1.blocks.4.conv2.bias', 'gcns.1.blocks.5.conv1.weight', 'gcns.1.blocks.5.conv1.loop_weight', 'gcns.1.blocks.5.conv1.bias', 'gcns.1.blocks.5.conv2.weight', 'gcns.1.blocks.5.conv2.loop_weight', 'gcns.1.blocks.5.conv2.bias', 'gcns.1.conv1.weight', 'gcns.1.conv1.loop_weight', 'gcns.1.conv1.bias', 'gcns.1.conv2.weight', 'gcns.1.conv2.loop_weight', 'gcns.1.conv2.bias', 'gcns.2.blocks.0.conv1.weight', 'gcns.2.blocks.0.conv1.loop_weight', 'gcns.2.blocks.0.conv1.bias', 'gcns.2.blocks.0.conv2.weight', 'gcns.2.blocks.0.conv2.loop_weight', 'gcns.2.blocks.0.conv2.bias', 'gcns.2.blocks.1.conv1.weight', 'gcns.2.blocks.1.conv1.loop_weight', 'gcns.2.blocks.1.conv1.bias', 'gcns.2.blocks.1.conv2.weight', 'gcns.2.blocks.1.conv2.loop_weight', 'gcns.2.blocks.1.conv2.bias', 'gcns.2.blocks.2.conv1.weight', 'gcns.2.blocks.2.conv1.loop_weight', 'gcns.2.blocks.2.conv1.bias', 'gcns.2.blocks.2.conv2.weight', 'gcns.2.blocks.2.conv2.loop_weight', 'gcns.2.blocks.2.conv2.bias', 'gcns.2.blocks.3.conv1.weight', 'gcns.2.blocks.3.conv1.loop_weight', 'gcns.2.blocks.3.conv1.bias', 'gcns.2.blocks.3.conv2.weight', 'gcns.2.blocks.3.conv2.loop_weight', 'gcns.2.blocks.3.conv2.bias', 'gcns.2.blocks.4.conv1.weight', 'gcns.2.blocks.4.conv1.loop_weight', 'gcns.2.blocks.4.conv1.bias', 'gcns.2.blocks.4.conv2.weight', 'gcns.2.blocks.4.conv2.loop_weight', 'gcns.2.blocks.4.conv2.bias', 'gcns.2.blocks.5.conv1.weight', 'gcns.2.blocks.5.conv1.loop_weight', 'gcns.2.blocks.5.conv1.bias', 'gcns.2.blocks.5.conv2.weight', 'gcns.2.blocks.5.conv2.loop_weight', 'gcns.2.blocks.5.conv2.bias', 'gcns.2.conv1.weight', 'gcns.2.conv1.loop_weight', 'gcns.2.conv1.bias', 'gcns.2.conv2.weight', 'gcns.2.conv2.loop_weight', 'gcns.2.conv2.bias', 'gconv.weight', 'gconv.loop_weight', 'gconv.bias'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('checkpoints/resnet.pth.tar')\t# 加载模型\n",
    "params=model.state_dict()\n",
    "print(checkpoint['model'].keys())\t\t\t\t\t\t\t\t\t\t\t\t# 查看模型元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints/resnet.pth.tar')\t# 加载模型\n",
    "params=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_pts\n",
      "nn_encoder.conv1.weight\n",
      "nn_encoder.bn1.weight\n",
      "nn_encoder.bn1.bias\n",
      "nn_encoder.bn1.running_mean\n",
      "nn_encoder.bn1.running_var\n",
      "nn_encoder.bn1.num_batches_tracked\n",
      "nn_encoder.layer1.0.conv1.weight\n",
      "nn_encoder.layer1.0.bn1.weight\n",
      "nn_encoder.layer1.0.bn1.bias\n",
      "nn_encoder.layer1.0.bn1.running_mean\n",
      "nn_encoder.layer1.0.bn1.running_var\n",
      "nn_encoder.layer1.0.bn1.num_batches_tracked\n",
      "nn_encoder.layer1.0.conv2.weight\n",
      "nn_encoder.layer1.0.bn2.weight\n",
      "nn_encoder.layer1.0.bn2.bias\n",
      "nn_encoder.layer1.0.bn2.running_mean\n",
      "nn_encoder.layer1.0.bn2.running_var\n",
      "nn_encoder.layer1.0.bn2.num_batches_tracked\n",
      "nn_encoder.layer1.0.conv3.weight\n",
      "nn_encoder.layer1.0.bn3.weight\n",
      "nn_encoder.layer1.0.bn3.bias\n",
      "nn_encoder.layer1.0.bn3.running_mean\n",
      "nn_encoder.layer1.0.bn3.running_var\n",
      "nn_encoder.layer1.0.bn3.num_batches_tracked\n",
      "nn_encoder.layer1.0.downsample.0.weight\n",
      "nn_encoder.layer1.0.downsample.1.weight\n",
      "nn_encoder.layer1.0.downsample.1.bias\n",
      "nn_encoder.layer1.0.downsample.1.running_mean\n",
      "nn_encoder.layer1.0.downsample.1.running_var\n",
      "nn_encoder.layer1.0.downsample.1.num_batches_tracked\n",
      "nn_encoder.layer1.1.conv1.weight\n",
      "nn_encoder.layer1.1.bn1.weight\n",
      "nn_encoder.layer1.1.bn1.bias\n",
      "nn_encoder.layer1.1.bn1.running_mean\n",
      "nn_encoder.layer1.1.bn1.running_var\n",
      "nn_encoder.layer1.1.bn1.num_batches_tracked\n",
      "nn_encoder.layer1.1.conv2.weight\n",
      "nn_encoder.layer1.1.bn2.weight\n",
      "nn_encoder.layer1.1.bn2.bias\n",
      "nn_encoder.layer1.1.bn2.running_mean\n",
      "nn_encoder.layer1.1.bn2.running_var\n",
      "nn_encoder.layer1.1.bn2.num_batches_tracked\n",
      "nn_encoder.layer1.1.conv3.weight\n",
      "nn_encoder.layer1.1.bn3.weight\n",
      "nn_encoder.layer1.1.bn3.bias\n",
      "nn_encoder.layer1.1.bn3.running_mean\n",
      "nn_encoder.layer1.1.bn3.running_var\n",
      "nn_encoder.layer1.1.bn3.num_batches_tracked\n",
      "nn_encoder.layer1.2.conv1.weight\n",
      "nn_encoder.layer1.2.bn1.weight\n",
      "nn_encoder.layer1.2.bn1.bias\n",
      "nn_encoder.layer1.2.bn1.running_mean\n",
      "nn_encoder.layer1.2.bn1.running_var\n",
      "nn_encoder.layer1.2.bn1.num_batches_tracked\n",
      "nn_encoder.layer1.2.conv2.weight\n",
      "nn_encoder.layer1.2.bn2.weight\n",
      "nn_encoder.layer1.2.bn2.bias\n",
      "nn_encoder.layer1.2.bn2.running_mean\n",
      "nn_encoder.layer1.2.bn2.running_var\n",
      "nn_encoder.layer1.2.bn2.num_batches_tracked\n",
      "nn_encoder.layer1.2.conv3.weight\n",
      "nn_encoder.layer1.2.bn3.weight\n",
      "nn_encoder.layer1.2.bn3.bias\n",
      "nn_encoder.layer1.2.bn3.running_mean\n",
      "nn_encoder.layer1.2.bn3.running_var\n",
      "nn_encoder.layer1.2.bn3.num_batches_tracked\n",
      "nn_encoder.layer2.0.conv1.weight\n",
      "nn_encoder.layer2.0.bn1.weight\n",
      "nn_encoder.layer2.0.bn1.bias\n",
      "nn_encoder.layer2.0.bn1.running_mean\n",
      "nn_encoder.layer2.0.bn1.running_var\n",
      "nn_encoder.layer2.0.bn1.num_batches_tracked\n",
      "nn_encoder.layer2.0.conv2.weight\n",
      "nn_encoder.layer2.0.bn2.weight\n",
      "nn_encoder.layer2.0.bn2.bias\n",
      "nn_encoder.layer2.0.bn2.running_mean\n",
      "nn_encoder.layer2.0.bn2.running_var\n",
      "nn_encoder.layer2.0.bn2.num_batches_tracked\n",
      "nn_encoder.layer2.0.conv3.weight\n",
      "nn_encoder.layer2.0.bn3.weight\n",
      "nn_encoder.layer2.0.bn3.bias\n",
      "nn_encoder.layer2.0.bn3.running_mean\n",
      "nn_encoder.layer2.0.bn3.running_var\n",
      "nn_encoder.layer2.0.bn3.num_batches_tracked\n",
      "nn_encoder.layer2.0.downsample.0.weight\n",
      "nn_encoder.layer2.0.downsample.1.weight\n",
      "nn_encoder.layer2.0.downsample.1.bias\n",
      "nn_encoder.layer2.0.downsample.1.running_mean\n",
      "nn_encoder.layer2.0.downsample.1.running_var\n",
      "nn_encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "nn_encoder.layer2.1.conv1.weight\n",
      "nn_encoder.layer2.1.bn1.weight\n",
      "nn_encoder.layer2.1.bn1.bias\n",
      "nn_encoder.layer2.1.bn1.running_mean\n",
      "nn_encoder.layer2.1.bn1.running_var\n",
      "nn_encoder.layer2.1.bn1.num_batches_tracked\n",
      "nn_encoder.layer2.1.conv2.weight\n",
      "nn_encoder.layer2.1.bn2.weight\n",
      "nn_encoder.layer2.1.bn2.bias\n",
      "nn_encoder.layer2.1.bn2.running_mean\n",
      "nn_encoder.layer2.1.bn2.running_var\n",
      "nn_encoder.layer2.1.bn2.num_batches_tracked\n",
      "nn_encoder.layer2.1.conv3.weight\n",
      "nn_encoder.layer2.1.bn3.weight\n",
      "nn_encoder.layer2.1.bn3.bias\n",
      "nn_encoder.layer2.1.bn3.running_mean\n",
      "nn_encoder.layer2.1.bn3.running_var\n",
      "nn_encoder.layer2.1.bn3.num_batches_tracked\n",
      "nn_encoder.layer2.2.conv1.weight\n",
      "nn_encoder.layer2.2.bn1.weight\n",
      "nn_encoder.layer2.2.bn1.bias\n",
      "nn_encoder.layer2.2.bn1.running_mean\n",
      "nn_encoder.layer2.2.bn1.running_var\n",
      "nn_encoder.layer2.2.bn1.num_batches_tracked\n",
      "nn_encoder.layer2.2.conv2.weight\n",
      "nn_encoder.layer2.2.bn2.weight\n",
      "nn_encoder.layer2.2.bn2.bias\n",
      "nn_encoder.layer2.2.bn2.running_mean\n",
      "nn_encoder.layer2.2.bn2.running_var\n",
      "nn_encoder.layer2.2.bn2.num_batches_tracked\n",
      "nn_encoder.layer2.2.conv3.weight\n",
      "nn_encoder.layer2.2.bn3.weight\n",
      "nn_encoder.layer2.2.bn3.bias\n",
      "nn_encoder.layer2.2.bn3.running_mean\n",
      "nn_encoder.layer2.2.bn3.running_var\n",
      "nn_encoder.layer2.2.bn3.num_batches_tracked\n",
      "nn_encoder.layer2.3.conv1.weight\n",
      "nn_encoder.layer2.3.bn1.weight\n",
      "nn_encoder.layer2.3.bn1.bias\n",
      "nn_encoder.layer2.3.bn1.running_mean\n",
      "nn_encoder.layer2.3.bn1.running_var\n",
      "nn_encoder.layer2.3.bn1.num_batches_tracked\n",
      "nn_encoder.layer2.3.conv2.weight\n",
      "nn_encoder.layer2.3.bn2.weight\n",
      "nn_encoder.layer2.3.bn2.bias\n",
      "nn_encoder.layer2.3.bn2.running_mean\n",
      "nn_encoder.layer2.3.bn2.running_var\n",
      "nn_encoder.layer2.3.bn2.num_batches_tracked\n",
      "nn_encoder.layer2.3.conv3.weight\n",
      "nn_encoder.layer2.3.bn3.weight\n",
      "nn_encoder.layer2.3.bn3.bias\n",
      "nn_encoder.layer2.3.bn3.running_mean\n",
      "nn_encoder.layer2.3.bn3.running_var\n",
      "nn_encoder.layer2.3.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.0.conv1.weight\n",
      "nn_encoder.layer3.0.bn1.weight\n",
      "nn_encoder.layer3.0.bn1.bias\n",
      "nn_encoder.layer3.0.bn1.running_mean\n",
      "nn_encoder.layer3.0.bn1.running_var\n",
      "nn_encoder.layer3.0.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.0.conv2.weight\n",
      "nn_encoder.layer3.0.bn2.weight\n",
      "nn_encoder.layer3.0.bn2.bias\n",
      "nn_encoder.layer3.0.bn2.running_mean\n",
      "nn_encoder.layer3.0.bn2.running_var\n",
      "nn_encoder.layer3.0.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.0.conv3.weight\n",
      "nn_encoder.layer3.0.bn3.weight\n",
      "nn_encoder.layer3.0.bn3.bias\n",
      "nn_encoder.layer3.0.bn3.running_mean\n",
      "nn_encoder.layer3.0.bn3.running_var\n",
      "nn_encoder.layer3.0.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.0.downsample.0.weight\n",
      "nn_encoder.layer3.0.downsample.1.weight\n",
      "nn_encoder.layer3.0.downsample.1.bias\n",
      "nn_encoder.layer3.0.downsample.1.running_mean\n",
      "nn_encoder.layer3.0.downsample.1.running_var\n",
      "nn_encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "nn_encoder.layer3.1.conv1.weight\n",
      "nn_encoder.layer3.1.bn1.weight\n",
      "nn_encoder.layer3.1.bn1.bias\n",
      "nn_encoder.layer3.1.bn1.running_mean\n",
      "nn_encoder.layer3.1.bn1.running_var\n",
      "nn_encoder.layer3.1.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.1.conv2.weight\n",
      "nn_encoder.layer3.1.bn2.weight\n",
      "nn_encoder.layer3.1.bn2.bias\n",
      "nn_encoder.layer3.1.bn2.running_mean\n",
      "nn_encoder.layer3.1.bn2.running_var\n",
      "nn_encoder.layer3.1.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.1.conv3.weight\n",
      "nn_encoder.layer3.1.bn3.weight\n",
      "nn_encoder.layer3.1.bn3.bias\n",
      "nn_encoder.layer3.1.bn3.running_mean\n",
      "nn_encoder.layer3.1.bn3.running_var\n",
      "nn_encoder.layer3.1.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.2.conv1.weight\n",
      "nn_encoder.layer3.2.bn1.weight\n",
      "nn_encoder.layer3.2.bn1.bias\n",
      "nn_encoder.layer3.2.bn1.running_mean\n",
      "nn_encoder.layer3.2.bn1.running_var\n",
      "nn_encoder.layer3.2.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.2.conv2.weight\n",
      "nn_encoder.layer3.2.bn2.weight\n",
      "nn_encoder.layer3.2.bn2.bias\n",
      "nn_encoder.layer3.2.bn2.running_mean\n",
      "nn_encoder.layer3.2.bn2.running_var\n",
      "nn_encoder.layer3.2.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.2.conv3.weight\n",
      "nn_encoder.layer3.2.bn3.weight\n",
      "nn_encoder.layer3.2.bn3.bias\n",
      "nn_encoder.layer3.2.bn3.running_mean\n",
      "nn_encoder.layer3.2.bn3.running_var\n",
      "nn_encoder.layer3.2.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.3.conv1.weight\n",
      "nn_encoder.layer3.3.bn1.weight\n",
      "nn_encoder.layer3.3.bn1.bias\n",
      "nn_encoder.layer3.3.bn1.running_mean\n",
      "nn_encoder.layer3.3.bn1.running_var\n",
      "nn_encoder.layer3.3.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.3.conv2.weight\n",
      "nn_encoder.layer3.3.bn2.weight\n",
      "nn_encoder.layer3.3.bn2.bias\n",
      "nn_encoder.layer3.3.bn2.running_mean\n",
      "nn_encoder.layer3.3.bn2.running_var\n",
      "nn_encoder.layer3.3.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.3.conv3.weight\n",
      "nn_encoder.layer3.3.bn3.weight\n",
      "nn_encoder.layer3.3.bn3.bias\n",
      "nn_encoder.layer3.3.bn3.running_mean\n",
      "nn_encoder.layer3.3.bn3.running_var\n",
      "nn_encoder.layer3.3.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.4.conv1.weight\n",
      "nn_encoder.layer3.4.bn1.weight\n",
      "nn_encoder.layer3.4.bn1.bias\n",
      "nn_encoder.layer3.4.bn1.running_mean\n",
      "nn_encoder.layer3.4.bn1.running_var\n",
      "nn_encoder.layer3.4.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.4.conv2.weight\n",
      "nn_encoder.layer3.4.bn2.weight\n",
      "nn_encoder.layer3.4.bn2.bias\n",
      "nn_encoder.layer3.4.bn2.running_mean\n",
      "nn_encoder.layer3.4.bn2.running_var\n",
      "nn_encoder.layer3.4.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.4.conv3.weight\n",
      "nn_encoder.layer3.4.bn3.weight\n",
      "nn_encoder.layer3.4.bn3.bias\n",
      "nn_encoder.layer3.4.bn3.running_mean\n",
      "nn_encoder.layer3.4.bn3.running_var\n",
      "nn_encoder.layer3.4.bn3.num_batches_tracked\n",
      "nn_encoder.layer3.5.conv1.weight\n",
      "nn_encoder.layer3.5.bn1.weight\n",
      "nn_encoder.layer3.5.bn1.bias\n",
      "nn_encoder.layer3.5.bn1.running_mean\n",
      "nn_encoder.layer3.5.bn1.running_var\n",
      "nn_encoder.layer3.5.bn1.num_batches_tracked\n",
      "nn_encoder.layer3.5.conv2.weight\n",
      "nn_encoder.layer3.5.bn2.weight\n",
      "nn_encoder.layer3.5.bn2.bias\n",
      "nn_encoder.layer3.5.bn2.running_mean\n",
      "nn_encoder.layer3.5.bn2.running_var\n",
      "nn_encoder.layer3.5.bn2.num_batches_tracked\n",
      "nn_encoder.layer3.5.conv3.weight\n",
      "nn_encoder.layer3.5.bn3.weight\n",
      "nn_encoder.layer3.5.bn3.bias\n",
      "nn_encoder.layer3.5.bn3.running_mean\n",
      "nn_encoder.layer3.5.bn3.running_var\n",
      "nn_encoder.layer3.5.bn3.num_batches_tracked\n",
      "nn_encoder.layer4.0.conv1.weight\n",
      "nn_encoder.layer4.0.bn1.weight\n",
      "nn_encoder.layer4.0.bn1.bias\n",
      "nn_encoder.layer4.0.bn1.running_mean\n",
      "nn_encoder.layer4.0.bn1.running_var\n",
      "nn_encoder.layer4.0.bn1.num_batches_tracked\n",
      "nn_encoder.layer4.0.conv2.weight\n",
      "nn_encoder.layer4.0.bn2.weight\n",
      "nn_encoder.layer4.0.bn2.bias\n",
      "nn_encoder.layer4.0.bn2.running_mean\n",
      "nn_encoder.layer4.0.bn2.running_var\n",
      "nn_encoder.layer4.0.bn2.num_batches_tracked\n",
      "nn_encoder.layer4.0.conv3.weight\n",
      "nn_encoder.layer4.0.bn3.weight\n",
      "nn_encoder.layer4.0.bn3.bias\n",
      "nn_encoder.layer4.0.bn3.running_mean\n",
      "nn_encoder.layer4.0.bn3.running_var\n",
      "nn_encoder.layer4.0.bn3.num_batches_tracked\n",
      "nn_encoder.layer4.0.downsample.0.weight\n",
      "nn_encoder.layer4.0.downsample.1.weight\n",
      "nn_encoder.layer4.0.downsample.1.bias\n",
      "nn_encoder.layer4.0.downsample.1.running_mean\n",
      "nn_encoder.layer4.0.downsample.1.running_var\n",
      "nn_encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "nn_encoder.layer4.1.conv1.weight\n",
      "nn_encoder.layer4.1.bn1.weight\n",
      "nn_encoder.layer4.1.bn1.bias\n",
      "nn_encoder.layer4.1.bn1.running_mean\n",
      "nn_encoder.layer4.1.bn1.running_var\n",
      "nn_encoder.layer4.1.bn1.num_batches_tracked\n",
      "nn_encoder.layer4.1.conv2.weight\n",
      "nn_encoder.layer4.1.bn2.weight\n",
      "nn_encoder.layer4.1.bn2.bias\n",
      "nn_encoder.layer4.1.bn2.running_mean\n",
      "nn_encoder.layer4.1.bn2.running_var\n",
      "nn_encoder.layer4.1.bn2.num_batches_tracked\n",
      "nn_encoder.layer4.1.conv3.weight\n",
      "nn_encoder.layer4.1.bn3.weight\n",
      "nn_encoder.layer4.1.bn3.bias\n",
      "nn_encoder.layer4.1.bn3.running_mean\n",
      "nn_encoder.layer4.1.bn3.running_var\n",
      "nn_encoder.layer4.1.bn3.num_batches_tracked\n",
      "nn_encoder.layer4.2.conv1.weight\n",
      "nn_encoder.layer4.2.bn1.weight\n",
      "nn_encoder.layer4.2.bn1.bias\n",
      "nn_encoder.layer4.2.bn1.running_mean\n",
      "nn_encoder.layer4.2.bn1.running_var\n",
      "nn_encoder.layer4.2.bn1.num_batches_tracked\n",
      "nn_encoder.layer4.2.conv2.weight\n",
      "nn_encoder.layer4.2.bn2.weight\n",
      "nn_encoder.layer4.2.bn2.bias\n",
      "nn_encoder.layer4.2.bn2.running_mean\n",
      "nn_encoder.layer4.2.bn2.running_var\n",
      "nn_encoder.layer4.2.bn2.num_batches_tracked\n",
      "nn_encoder.layer4.2.conv3.weight\n",
      "nn_encoder.layer4.2.bn3.weight\n",
      "nn_encoder.layer4.2.bn3.bias\n",
      "nn_encoder.layer4.2.bn3.running_mean\n",
      "nn_encoder.layer4.2.bn3.running_var\n",
      "nn_encoder.layer4.2.bn3.num_batches_tracked\n",
      "nn_encoder.fc.weight\n",
      "nn_encoder.fc.bias\n",
      "gcns.0.blocks.0.conv1.adj_mat\n",
      "gcns.0.blocks.0.conv1.weight\n",
      "gcns.0.blocks.0.conv1.loop_weight\n",
      "gcns.0.blocks.0.conv1.bias\n",
      "gcns.0.blocks.0.conv2.adj_mat\n",
      "gcns.0.blocks.0.conv2.weight\n",
      "gcns.0.blocks.0.conv2.loop_weight\n",
      "gcns.0.blocks.0.conv2.bias\n",
      "gcns.0.blocks.1.conv1.adj_mat\n",
      "gcns.0.blocks.1.conv1.weight\n",
      "gcns.0.blocks.1.conv1.loop_weight\n",
      "gcns.0.blocks.1.conv1.bias\n",
      "gcns.0.blocks.1.conv2.adj_mat\n",
      "gcns.0.blocks.1.conv2.weight\n",
      "gcns.0.blocks.1.conv2.loop_weight\n",
      "gcns.0.blocks.1.conv2.bias\n",
      "gcns.0.blocks.2.conv1.adj_mat\n",
      "gcns.0.blocks.2.conv1.weight\n",
      "gcns.0.blocks.2.conv1.loop_weight\n",
      "gcns.0.blocks.2.conv1.bias\n",
      "gcns.0.blocks.2.conv2.adj_mat\n",
      "gcns.0.blocks.2.conv2.weight\n",
      "gcns.0.blocks.2.conv2.loop_weight\n",
      "gcns.0.blocks.2.conv2.bias\n",
      "gcns.0.blocks.3.conv1.adj_mat\n",
      "gcns.0.blocks.3.conv1.weight\n",
      "gcns.0.blocks.3.conv1.loop_weight\n",
      "gcns.0.blocks.3.conv1.bias\n",
      "gcns.0.blocks.3.conv2.adj_mat\n",
      "gcns.0.blocks.3.conv2.weight\n",
      "gcns.0.blocks.3.conv2.loop_weight\n",
      "gcns.0.blocks.3.conv2.bias\n",
      "gcns.0.blocks.4.conv1.adj_mat\n",
      "gcns.0.blocks.4.conv1.weight\n",
      "gcns.0.blocks.4.conv1.loop_weight\n",
      "gcns.0.blocks.4.conv1.bias\n",
      "gcns.0.blocks.4.conv2.adj_mat\n",
      "gcns.0.blocks.4.conv2.weight\n",
      "gcns.0.blocks.4.conv2.loop_weight\n",
      "gcns.0.blocks.4.conv2.bias\n",
      "gcns.0.blocks.5.conv1.adj_mat\n",
      "gcns.0.blocks.5.conv1.weight\n",
      "gcns.0.blocks.5.conv1.loop_weight\n",
      "gcns.0.blocks.5.conv1.bias\n",
      "gcns.0.blocks.5.conv2.adj_mat\n",
      "gcns.0.blocks.5.conv2.weight\n",
      "gcns.0.blocks.5.conv2.loop_weight\n",
      "gcns.0.blocks.5.conv2.bias\n",
      "gcns.0.conv1.adj_mat\n",
      "gcns.0.conv1.weight\n",
      "gcns.0.conv1.loop_weight\n",
      "gcns.0.conv1.bias\n",
      "gcns.0.conv2.adj_mat\n",
      "gcns.0.conv2.weight\n",
      "gcns.0.conv2.loop_weight\n",
      "gcns.0.conv2.bias\n",
      "gcns.1.blocks.0.conv1.adj_mat\n",
      "gcns.1.blocks.0.conv1.weight\n",
      "gcns.1.blocks.0.conv1.loop_weight\n",
      "gcns.1.blocks.0.conv1.bias\n",
      "gcns.1.blocks.0.conv2.adj_mat\n",
      "gcns.1.blocks.0.conv2.weight\n",
      "gcns.1.blocks.0.conv2.loop_weight\n",
      "gcns.1.blocks.0.conv2.bias\n",
      "gcns.1.blocks.1.conv1.adj_mat\n",
      "gcns.1.blocks.1.conv1.weight\n",
      "gcns.1.blocks.1.conv1.loop_weight\n",
      "gcns.1.blocks.1.conv1.bias\n",
      "gcns.1.blocks.1.conv2.adj_mat\n",
      "gcns.1.blocks.1.conv2.weight\n",
      "gcns.1.blocks.1.conv2.loop_weight\n",
      "gcns.1.blocks.1.conv2.bias\n",
      "gcns.1.blocks.2.conv1.adj_mat\n",
      "gcns.1.blocks.2.conv1.weight\n",
      "gcns.1.blocks.2.conv1.loop_weight\n",
      "gcns.1.blocks.2.conv1.bias\n",
      "gcns.1.blocks.2.conv2.adj_mat\n",
      "gcns.1.blocks.2.conv2.weight\n",
      "gcns.1.blocks.2.conv2.loop_weight\n",
      "gcns.1.blocks.2.conv2.bias\n",
      "gcns.1.blocks.3.conv1.adj_mat\n",
      "gcns.1.blocks.3.conv1.weight\n",
      "gcns.1.blocks.3.conv1.loop_weight\n",
      "gcns.1.blocks.3.conv1.bias\n",
      "gcns.1.blocks.3.conv2.adj_mat\n",
      "gcns.1.blocks.3.conv2.weight\n",
      "gcns.1.blocks.3.conv2.loop_weight\n",
      "gcns.1.blocks.3.conv2.bias\n",
      "gcns.1.blocks.4.conv1.adj_mat\n",
      "gcns.1.blocks.4.conv1.weight\n",
      "gcns.1.blocks.4.conv1.loop_weight\n",
      "gcns.1.blocks.4.conv1.bias\n",
      "gcns.1.blocks.4.conv2.adj_mat\n",
      "gcns.1.blocks.4.conv2.weight\n",
      "gcns.1.blocks.4.conv2.loop_weight\n",
      "gcns.1.blocks.4.conv2.bias\n",
      "gcns.1.blocks.5.conv1.adj_mat\n",
      "gcns.1.blocks.5.conv1.weight\n",
      "gcns.1.blocks.5.conv1.loop_weight\n",
      "gcns.1.blocks.5.conv1.bias\n",
      "gcns.1.blocks.5.conv2.adj_mat\n",
      "gcns.1.blocks.5.conv2.weight\n",
      "gcns.1.blocks.5.conv2.loop_weight\n",
      "gcns.1.blocks.5.conv2.bias\n",
      "gcns.1.conv1.adj_mat\n",
      "gcns.1.conv1.weight\n",
      "gcns.1.conv1.loop_weight\n",
      "gcns.1.conv1.bias\n",
      "gcns.1.conv2.adj_mat\n",
      "gcns.1.conv2.weight\n",
      "gcns.1.conv2.loop_weight\n",
      "gcns.1.conv2.bias\n",
      "gcns.2.blocks.0.conv1.adj_mat\n",
      "gcns.2.blocks.0.conv1.weight\n",
      "gcns.2.blocks.0.conv1.loop_weight\n",
      "gcns.2.blocks.0.conv1.bias\n",
      "gcns.2.blocks.0.conv2.adj_mat\n",
      "gcns.2.blocks.0.conv2.weight\n",
      "gcns.2.blocks.0.conv2.loop_weight\n",
      "gcns.2.blocks.0.conv2.bias\n",
      "gcns.2.blocks.1.conv1.adj_mat\n",
      "gcns.2.blocks.1.conv1.weight\n",
      "gcns.2.blocks.1.conv1.loop_weight\n",
      "gcns.2.blocks.1.conv1.bias\n",
      "gcns.2.blocks.1.conv2.adj_mat\n",
      "gcns.2.blocks.1.conv2.weight\n",
      "gcns.2.blocks.1.conv2.loop_weight\n",
      "gcns.2.blocks.1.conv2.bias\n",
      "gcns.2.blocks.2.conv1.adj_mat\n",
      "gcns.2.blocks.2.conv1.weight\n",
      "gcns.2.blocks.2.conv1.loop_weight\n",
      "gcns.2.blocks.2.conv1.bias\n",
      "gcns.2.blocks.2.conv2.adj_mat\n",
      "gcns.2.blocks.2.conv2.weight\n",
      "gcns.2.blocks.2.conv2.loop_weight\n",
      "gcns.2.blocks.2.conv2.bias\n",
      "gcns.2.blocks.3.conv1.adj_mat\n",
      "gcns.2.blocks.3.conv1.weight\n",
      "gcns.2.blocks.3.conv1.loop_weight\n",
      "gcns.2.blocks.3.conv1.bias\n",
      "gcns.2.blocks.3.conv2.adj_mat\n",
      "gcns.2.blocks.3.conv2.weight\n",
      "gcns.2.blocks.3.conv2.loop_weight\n",
      "gcns.2.blocks.3.conv2.bias\n",
      "gcns.2.blocks.4.conv1.adj_mat\n",
      "gcns.2.blocks.4.conv1.weight\n",
      "gcns.2.blocks.4.conv1.loop_weight\n",
      "gcns.2.blocks.4.conv1.bias\n",
      "gcns.2.blocks.4.conv2.adj_mat\n",
      "gcns.2.blocks.4.conv2.weight\n",
      "gcns.2.blocks.4.conv2.loop_weight\n",
      "gcns.2.blocks.4.conv2.bias\n",
      "gcns.2.blocks.5.conv1.adj_mat\n",
      "gcns.2.blocks.5.conv1.weight\n",
      "gcns.2.blocks.5.conv1.loop_weight\n",
      "gcns.2.blocks.5.conv1.bias\n",
      "gcns.2.blocks.5.conv2.adj_mat\n",
      "gcns.2.blocks.5.conv2.weight\n",
      "gcns.2.blocks.5.conv2.loop_weight\n",
      "gcns.2.blocks.5.conv2.bias\n",
      "gcns.2.conv1.adj_mat\n",
      "gcns.2.conv1.weight\n",
      "gcns.2.conv1.loop_weight\n",
      "gcns.2.conv1.bias\n",
      "gcns.2.conv2.adj_mat\n",
      "gcns.2.conv2.weight\n",
      "gcns.2.conv2.loop_weight\n",
      "gcns.2.conv2.bias\n",
      "gcns.3.blocks.0.conv1.adj_mat\n",
      "gcns.3.blocks.0.conv1.weight\n",
      "gcns.3.blocks.0.conv1.loop_weight\n",
      "gcns.3.blocks.0.conv1.bias\n",
      "gcns.3.blocks.0.conv2.adj_mat\n",
      "gcns.3.blocks.0.conv2.weight\n",
      "gcns.3.blocks.0.conv2.loop_weight\n",
      "gcns.3.blocks.0.conv2.bias\n",
      "gcns.3.blocks.1.conv1.adj_mat\n",
      "gcns.3.blocks.1.conv1.weight\n",
      "gcns.3.blocks.1.conv1.loop_weight\n",
      "gcns.3.blocks.1.conv1.bias\n",
      "gcns.3.blocks.1.conv2.adj_mat\n",
      "gcns.3.blocks.1.conv2.weight\n",
      "gcns.3.blocks.1.conv2.loop_weight\n",
      "gcns.3.blocks.1.conv2.bias\n",
      "gcns.3.blocks.2.conv1.adj_mat\n",
      "gcns.3.blocks.2.conv1.weight\n",
      "gcns.3.blocks.2.conv1.loop_weight\n",
      "gcns.3.blocks.2.conv1.bias\n",
      "gcns.3.blocks.2.conv2.adj_mat\n",
      "gcns.3.blocks.2.conv2.weight\n",
      "gcns.3.blocks.2.conv2.loop_weight\n",
      "gcns.3.blocks.2.conv2.bias\n",
      "gcns.3.blocks.3.conv1.adj_mat\n",
      "gcns.3.blocks.3.conv1.weight\n",
      "gcns.3.blocks.3.conv1.loop_weight\n",
      "gcns.3.blocks.3.conv1.bias\n",
      "gcns.3.blocks.3.conv2.adj_mat\n",
      "gcns.3.blocks.3.conv2.weight\n",
      "gcns.3.blocks.3.conv2.loop_weight\n",
      "gcns.3.blocks.3.conv2.bias\n",
      "gcns.3.blocks.4.conv1.adj_mat\n",
      "gcns.3.blocks.4.conv1.weight\n",
      "gcns.3.blocks.4.conv1.loop_weight\n",
      "gcns.3.blocks.4.conv1.bias\n",
      "gcns.3.blocks.4.conv2.adj_mat\n",
      "gcns.3.blocks.4.conv2.weight\n",
      "gcns.3.blocks.4.conv2.loop_weight\n",
      "gcns.3.blocks.4.conv2.bias\n",
      "gcns.3.blocks.5.conv1.adj_mat\n",
      "gcns.3.blocks.5.conv1.weight\n",
      "gcns.3.blocks.5.conv1.loop_weight\n",
      "gcns.3.blocks.5.conv1.bias\n",
      "gcns.3.blocks.5.conv2.adj_mat\n",
      "gcns.3.blocks.5.conv2.weight\n",
      "gcns.3.blocks.5.conv2.loop_weight\n",
      "gcns.3.blocks.5.conv2.bias\n",
      "gcns.3.conv1.adj_mat\n",
      "gcns.3.conv1.weight\n",
      "gcns.3.conv1.loop_weight\n",
      "gcns.3.conv1.bias\n",
      "gcns.3.conv2.adj_mat\n",
      "gcns.3.conv2.weight\n",
      "gcns.3.conv2.loop_weight\n",
      "gcns.3.conv2.bias\n",
      "gconv.adj_mat\n",
      "gconv.weight\n",
      "gconv.loop_weight\n",
      "gconv.bias\n"
     ]
    }
   ],
   "source": [
    "for k,v in params.items():\n",
    "    print(k) #打印网络中的变量名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_rename(old_string, new_string, start, end):\n",
    "    new_string = old_string[:start] + new_string + old_string[end:]\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigmodule_list(children):\n",
    "    Bigmodule = []\n",
    "    for name, module in children:\n",
    "        Bigmodule.append(name)\n",
    "    return Bigmodule\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_state_dict(pretrained_dict, model_dict,submodule, old_prefix, new_prefix):\n",
    "    state_dict = {}\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if  k.startswith(\"nn_encoder\"):\n",
    "            print(\"Missing key(s) in state_dict :{}\".format(k))\n",
    "        else:\n",
    "            if k not in old_prefix:\n",
    "            # state_dict.setdefault(k, v)\n",
    "                state_dict[k] = v\n",
    "            else:\n",
    "                for o, n in zip(old_prefix, new_prefix):\n",
    "                    prefix = k[:len(o)]\n",
    "                    if prefix == o:\n",
    "                        kk = string_rename(old_string=k, new_string=n, start=0, end=len(o))\n",
    "                        print(\"rename layer modules:{}-->{}\".format(k, kk))\n",
    "                        state_dict[kk] = v\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing key(s) in state_dict :nn_encoder.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.0.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.0.downsample.1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.1.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer1.2.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.0.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.1.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.2.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer2.3.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.0.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.1.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.2.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.3.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.4.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer3.5.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.0.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.1.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.conv1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn1.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn1.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn1.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn1.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn1.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.conv2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn2.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn2.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn2.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn2.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn2.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.conv3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn3.weight\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn3.bias\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn3.running_mean\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn3.running_var\n",
      "Missing key(s) in state_dict :nn_encoder.layer4.2.bn3.num_batches_tracked\n",
      "Missing key(s) in state_dict :nn_encoder.fc.weight\n",
      "Missing key(s) in state_dict :nn_encoder.fc.bias\n",
      "rename layer modules:gcns.2.conv2.weight-->gcns.3.conv2.weight\n",
      "rename layer modules:gcns.2.conv2.loop_weight-->gcns.3.conv2.loop_weight\n",
      "rename layer modules:gcns.2.conv2.bias-->gcns.3.conv2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=['nn_encoder.conv1.weight', 'nn_encoder.bn1.weight', 'nn_encoder.bn1.bias', 'nn_encoder.bn1.running_mean', 'nn_encoder.bn1.running_var', 'nn_encoder.layer1.0.conv1.weight', 'nn_encoder.layer1.0.bn1.weight', 'nn_encoder.layer1.0.bn1.bias', 'nn_encoder.layer1.0.bn1.running_mean', 'nn_encoder.layer1.0.bn1.running_var', 'nn_encoder.layer1.0.conv2.weight', 'nn_encoder.layer1.0.bn2.weight', 'nn_encoder.layer1.0.bn2.bias', 'nn_encoder.layer1.0.bn2.running_mean', 'nn_encoder.layer1.0.bn2.running_var', 'nn_encoder.layer1.0.conv3.weight', 'nn_encoder.layer1.0.bn3.weight', 'nn_encoder.layer1.0.bn3.bias', 'nn_encoder.layer1.0.bn3.running_mean', 'nn_encoder.layer1.0.bn3.running_var', 'nn_encoder.layer1.0.downsample.0.weight', 'nn_encoder.layer1.0.downsample.1.weight', 'nn_encoder.layer1.0.downsample.1.bias', 'nn_encoder.layer1.0.downsample.1.running_mean', 'nn_encoder.layer1.0.downsample.1.running_var', 'nn_encoder.layer1.1.conv1.weight', 'nn_encoder.layer1.1.bn1.weight', 'nn_encoder.layer1.1.bn1.bias', 'nn_encoder.layer1.1.bn1.running_mean', 'nn_encoder.layer1.1.bn1.running_var', 'nn_encoder.layer1.1.conv2.weight', 'nn_encoder.layer1.1.bn2.weight', 'nn_encoder.layer1.1.bn2.bias', 'nn_encoder.layer1.1.bn2.running_mean', 'nn_encoder.layer1.1.bn2.running_var', 'nn_encoder.layer1.1.conv3.weight', 'nn_encoder.layer1.1.bn3.weight', 'nn_encoder.layer1.1.bn3.bias', 'nn_encoder.layer1.1.bn3.running_mean', 'nn_encoder.layer1.1.bn3.running_var', 'nn_encoder.layer1.2.conv1.weight', 'nn_encoder.layer1.2.bn1.weight', 'nn_encoder.layer1.2.bn1.bias', 'nn_encoder.layer1.2.bn1.running_mean', 'nn_encoder.layer1.2.bn1.running_var', 'nn_encoder.layer1.2.conv2.weight', 'nn_encoder.layer1.2.bn2.weight', 'nn_encoder.layer1.2.bn2.bias', 'nn_encoder.layer1.2.bn2.running_mean', 'nn_encoder.layer1.2.bn2.running_var', 'nn_encoder.layer1.2.conv3.weight', 'nn_encoder.layer1.2.bn3.weight', 'nn_encoder.layer1.2.bn3.bias', 'nn_encoder.layer1.2.bn3.running_mean', 'nn_encoder.layer1.2.bn3.running_var', 'nn_encoder.layer2.0.conv1.weight', 'nn_encoder.layer2.0.bn1.weight', 'nn_encoder.layer2.0.bn1.bias', 'nn_encoder.layer2.0.bn1.running_mean', 'nn_encoder.layer2.0.bn1.running_var', 'nn_encoder.layer2.0.conv2.weight', 'nn_encoder.layer2.0.bn2.weight', 'nn_encoder.layer2.0.bn2.bias', 'nn_encoder.layer2.0.bn2.running_mean', 'nn_encoder.layer2.0.bn2.running_var', 'nn_encoder.layer2.0.conv3.weight', 'nn_encoder.layer2.0.bn3.weight', 'nn_encoder.layer2.0.bn3.bias', 'nn_encoder.layer2.0.bn3.running_mean', 'nn_encoder.layer2.0.bn3.running_var', 'nn_encoder.layer2.0.downsample.0.weight', 'nn_encoder.layer2.0.downsample.1.weight', 'nn_encoder.layer2.0.downsample.1.bias', 'nn_encoder.layer2.0.downsample.1.running_mean', 'nn_encoder.layer2.0.downsample.1.running_var', 'nn_encoder.layer2.1.conv1.weight', 'nn_encoder.layer2.1.bn1.weight', 'nn_encoder.layer2.1.bn1.bias', 'nn_encoder.layer2.1.bn1.running_mean', 'nn_encoder.layer2.1.bn1.running_var', 'nn_encoder.layer2.1.conv2.weight', 'nn_encoder.layer2.1.bn2.weight', 'nn_encoder.layer2.1.bn2.bias', 'nn_encoder.layer2.1.bn2.running_mean', 'nn_encoder.layer2.1.bn2.running_var', 'nn_encoder.layer2.1.conv3.weight', 'nn_encoder.layer2.1.bn3.weight', 'nn_encoder.layer2.1.bn3.bias', 'nn_encoder.layer2.1.bn3.running_mean', 'nn_encoder.layer2.1.bn3.running_var', 'nn_encoder.layer2.2.conv1.weight', 'nn_encoder.layer2.2.bn1.weight', 'nn_encoder.layer2.2.bn1.bias', 'nn_encoder.layer2.2.bn1.running_mean', 'nn_encoder.layer2.2.bn1.running_var', 'nn_encoder.layer2.2.conv2.weight', 'nn_encoder.layer2.2.bn2.weight', 'nn_encoder.layer2.2.bn2.bias', 'nn_encoder.layer2.2.bn2.running_mean', 'nn_encoder.layer2.2.bn2.running_var', 'nn_encoder.layer2.2.conv3.weight', 'nn_encoder.layer2.2.bn3.weight', 'nn_encoder.layer2.2.bn3.bias', 'nn_encoder.layer2.2.bn3.running_mean', 'nn_encoder.layer2.2.bn3.running_var', 'nn_encoder.layer2.3.conv1.weight', 'nn_encoder.layer2.3.bn1.weight', 'nn_encoder.layer2.3.bn1.bias', 'nn_encoder.layer2.3.bn1.running_mean', 'nn_encoder.layer2.3.bn1.running_var', 'nn_encoder.layer2.3.conv2.weight', 'nn_encoder.layer2.3.bn2.weight', 'nn_encoder.layer2.3.bn2.bias', 'nn_encoder.layer2.3.bn2.running_mean', 'nn_encoder.layer2.3.bn2.running_var', 'nn_encoder.layer2.3.conv3.weight', 'nn_encoder.layer2.3.bn3.weight', 'nn_encoder.layer2.3.bn3.bias', 'nn_encoder.layer2.3.bn3.running_mean', 'nn_encoder.layer2.3.bn3.running_var', 'nn_encoder.layer3.0.conv1.weight', 'nn_encoder.layer3.0.bn1.weight', 'nn_encoder.layer3.0.bn1.bias', 'nn_encoder.layer3.0.bn1.running_mean', 'nn_encoder.layer3.0.bn1.running_var', 'nn_encoder.layer3.0.conv2.weight', 'nn_encoder.layer3.0.bn2.weight', 'nn_encoder.layer3.0.bn2.bias', 'nn_encoder.layer3.0.bn2.running_mean', 'nn_encoder.layer3.0.bn2.running_var', 'nn_encoder.layer3.0.conv3.weight', 'nn_encoder.layer3.0.bn3.weight', 'nn_encoder.layer3.0.bn3.bias', 'nn_encoder.layer3.0.bn3.running_mean', 'nn_encoder.layer3.0.bn3.running_var', 'nn_encoder.layer3.0.downsample.0.weight', 'nn_encoder.layer3.0.downsample.1.weight', 'nn_encoder.layer3.0.downsample.1.bias', 'nn_encoder.layer3.0.downsample.1.running_mean', 'nn_encoder.layer3.0.downsample.1.running_var', 'nn_encoder.layer3.1.conv1.weight', 'nn_encoder.layer3.1.bn1.weight', 'nn_encoder.layer3.1.bn1.bias', 'nn_encoder.layer3.1.bn1.running_mean', 'nn_encoder.layer3.1.bn1.running_var', 'nn_encoder.layer3.1.conv2.weight', 'nn_encoder.layer3.1.bn2.weight', 'nn_encoder.layer3.1.bn2.bias', 'nn_encoder.layer3.1.bn2.running_mean', 'nn_encoder.layer3.1.bn2.running_var', 'nn_encoder.layer3.1.conv3.weight', 'nn_encoder.layer3.1.bn3.weight', 'nn_encoder.layer3.1.bn3.bias', 'nn_encoder.layer3.1.bn3.running_mean', 'nn_encoder.layer3.1.bn3.running_var', 'nn_encoder.layer3.2.conv1.weight', 'nn_encoder.layer3.2.bn1.weight', 'nn_encoder.layer3.2.bn1.bias', 'nn_encoder.layer3.2.bn1.running_mean', 'nn_encoder.layer3.2.bn1.running_var', 'nn_encoder.layer3.2.conv2.weight', 'nn_encoder.layer3.2.bn2.weight', 'nn_encoder.layer3.2.bn2.bias', 'nn_encoder.layer3.2.bn2.running_mean', 'nn_encoder.layer3.2.bn2.running_var', 'nn_encoder.layer3.2.conv3.weight', 'nn_encoder.layer3.2.bn3.weight', 'nn_encoder.layer3.2.bn3.bias', 'nn_encoder.layer3.2.bn3.running_mean', 'nn_encoder.layer3.2.bn3.running_var', 'nn_encoder.layer3.3.conv1.weight', 'nn_encoder.layer3.3.bn1.weight', 'nn_encoder.layer3.3.bn1.bias', 'nn_encoder.layer3.3.bn1.running_mean', 'nn_encoder.layer3.3.bn1.running_var', 'nn_encoder.layer3.3.conv2.weight', 'nn_encoder.layer3.3.bn2.weight', 'nn_encoder.layer3.3.bn2.bias', 'nn_encoder.layer3.3.bn2.running_mean', 'nn_encoder.layer3.3.bn2.running_var', 'nn_encoder.layer3.3.conv3.weight', 'nn_encoder.layer3.3.bn3.weight', 'nn_encoder.layer3.3.bn3.bias', 'nn_encoder.layer3.3.bn3.running_mean', 'nn_encoder.layer3.3.bn3.running_var', 'nn_encoder.layer3.4.conv1.weight', 'nn_encoder.layer3.4.bn1.weight', 'nn_encoder.layer3.4.bn1.bias', 'nn_encoder.layer3.4.bn1.running_mean', 'nn_encoder.layer3.4.bn1.running_var', 'nn_encoder.layer3.4.conv2.weight', 'nn_encoder.layer3.4.bn2.weight', 'nn_encoder.layer3.4.bn2.bias', 'nn_encoder.layer3.4.bn2.running_mean', 'nn_encoder.layer3.4.bn2.running_var', 'nn_encoder.layer3.4.conv3.weight', 'nn_encoder.layer3.4.bn3.weight', 'nn_encoder.layer3.4.bn3.bias', 'nn_encoder.layer3.4.bn3.running_mean', 'nn_encoder.layer3.4.bn3.running_var', 'nn_encoder.layer3.5.conv1.weight', 'nn_encoder.layer3.5.bn1.weight', 'nn_encoder.layer3.5.bn1.bias', 'nn_encoder.layer3.5.bn1.running_mean', 'nn_encoder.layer3.5.bn1.running_var', 'nn_encoder.layer3.5.conv2.weight', 'nn_encoder.layer3.5.bn2.weight', 'nn_encoder.layer3.5.bn2.bias', 'nn_encoder.layer3.5.bn2.running_mean', 'nn_encoder.layer3.5.bn2.running_var', 'nn_encoder.layer3.5.conv3.weight', 'nn_encoder.layer3.5.bn3.weight', 'nn_encoder.layer3.5.bn3.bias', 'nn_encoder.layer3.5.bn3.running_mean', 'nn_encoder.layer3.5.bn3.running_var', 'nn_encoder.layer4.0.conv1.weight', 'nn_encoder.layer4.0.bn1.weight', 'nn_encoder.layer4.0.bn1.bias', 'nn_encoder.layer4.0.bn1.running_mean', 'nn_encoder.layer4.0.bn1.running_var', 'nn_encoder.layer4.0.conv2.weight', 'nn_encoder.layer4.0.bn2.weight', 'nn_encoder.layer4.0.bn2.bias', 'nn_encoder.layer4.0.bn2.running_mean', 'nn_encoder.layer4.0.bn2.running_var', 'nn_encoder.layer4.0.conv3.weight', 'nn_encoder.layer4.0.bn3.weight', 'nn_encoder.layer4.0.bn3.bias', 'nn_encoder.layer4.0.bn3.running_mean', 'nn_encoder.layer4.0.bn3.running_var', 'nn_encoder.layer4.0.downsample.0.weight', 'nn_encoder.layer4.0.downsample.1.weight', 'nn_encoder.layer4.0.downsample.1.bias', 'nn_encoder.layer4.0.downsample.1.running_mean', 'nn_encoder.layer4.0.downsample.1.running_var', 'nn_encoder.layer4.1.conv1.weight', 'nn_encoder.layer4.1.bn1.weight', 'nn_encoder.layer4.1.bn1.bias', 'nn_encoder.layer4.1.bn1.running_mean', 'nn_encoder.layer4.1.bn1.running_var', 'nn_encoder.layer4.1.conv2.weight', 'nn_encoder.layer4.1.bn2.weight', 'nn_encoder.layer4.1.bn2.bias', 'nn_encoder.layer4.1.bn2.running_mean', 'nn_encoder.layer4.1.bn2.running_var', 'nn_encoder.layer4.1.conv3.weight', 'nn_encoder.layer4.1.bn3.weight', 'nn_encoder.layer4.1.bn3.bias', 'nn_encoder.layer4.1.bn3.running_mean', 'nn_encoder.layer4.1.bn3.running_var', 'nn_encoder.layer4.2.conv1.weight', 'nn_encoder.layer4.2.bn1.weight', 'nn_encoder.layer4.2.bn1.bias', 'nn_encoder.layer4.2.bn1.running_mean', 'nn_encoder.layer4.2.bn1.running_var', 'nn_encoder.layer4.2.conv2.weight', 'nn_encoder.layer4.2.bn2.weight', 'nn_encoder.layer4.2.bn2.bias', 'nn_encoder.layer4.2.bn2.running_mean', 'nn_encoder.layer4.2.bn2.running_var', 'nn_encoder.layer4.2.conv3.weight', 'nn_encoder.layer4.2.bn3.weight', 'nn_encoder.layer4.2.bn3.bias', 'nn_encoder.layer4.2.bn3.running_mean', 'nn_encoder.layer4.2.bn3.running_var', 'nn_encoder.fc.weight', 'nn_encoder.fc.bias', 'gcns.0.blocks.0.conv1.adj_mat', 'gcns.0.blocks.0.conv2.adj_mat', 'gcns.0.blocks.1.conv1.adj_mat', 'gcns.0.blocks.1.conv2.adj_mat', 'gcns.0.blocks.2.conv1.adj_mat', 'gcns.0.blocks.2.conv2.adj_mat', 'gcns.0.blocks.3.conv1.adj_mat', 'gcns.0.blocks.3.conv2.adj_mat', 'gcns.0.blocks.4.conv1.adj_mat', 'gcns.0.blocks.4.conv2.adj_mat', 'gcns.0.blocks.5.conv1.adj_mat', 'gcns.0.blocks.5.conv2.adj_mat', 'gcns.0.conv1.adj_mat', 'gcns.0.conv2.adj_mat', 'gcns.1.blocks.0.conv1.adj_mat', 'gcns.1.blocks.0.conv2.adj_mat', 'gcns.1.blocks.1.conv1.adj_mat', 'gcns.1.blocks.1.conv2.adj_mat', 'gcns.1.blocks.2.conv1.adj_mat', 'gcns.1.blocks.2.conv2.adj_mat', 'gcns.1.blocks.3.conv1.adj_mat', 'gcns.1.blocks.3.conv2.adj_mat', 'gcns.1.blocks.4.conv1.adj_mat', 'gcns.1.blocks.4.conv2.adj_mat', 'gcns.1.blocks.5.conv1.adj_mat', 'gcns.1.blocks.5.conv2.adj_mat', 'gcns.1.conv1.adj_mat', 'gcns.1.conv2.adj_mat', 'gcns.2.blocks.0.conv1.adj_mat', 'gcns.2.blocks.0.conv2.adj_mat', 'gcns.2.blocks.1.conv1.adj_mat', 'gcns.2.blocks.1.conv2.adj_mat', 'gcns.2.blocks.2.conv1.adj_mat', 'gcns.2.blocks.2.conv2.adj_mat', 'gcns.2.blocks.3.conv1.adj_mat', 'gcns.2.blocks.3.conv2.adj_mat', 'gcns.2.blocks.4.conv1.adj_mat', 'gcns.2.blocks.4.conv2.adj_mat', 'gcns.2.blocks.5.conv1.adj_mat', 'gcns.2.blocks.5.conv2.adj_mat', 'gcns.2.conv1.adj_mat', 'gcns.2.conv2.adj_mat', 'gcns.2.conv2.weight', 'gcns.2.conv2.loop_weight', 'gcns.2.conv2.bias', 'gcns.3.blocks.0.conv1.adj_mat', 'gcns.3.blocks.0.conv1.weight', 'gcns.3.blocks.0.conv1.loop_weight', 'gcns.3.blocks.0.conv1.bias', 'gcns.3.blocks.0.conv2.adj_mat', 'gcns.3.blocks.0.conv2.weight', 'gcns.3.blocks.0.conv2.loop_weight', 'gcns.3.blocks.0.conv2.bias', 'gcns.3.blocks.1.conv1.adj_mat', 'gcns.3.blocks.1.conv1.weight', 'gcns.3.blocks.1.conv1.loop_weight', 'gcns.3.blocks.1.conv1.bias', 'gcns.3.blocks.1.conv2.adj_mat', 'gcns.3.blocks.1.conv2.weight', 'gcns.3.blocks.1.conv2.loop_weight', 'gcns.3.blocks.1.conv2.bias', 'gcns.3.blocks.2.conv1.adj_mat', 'gcns.3.blocks.2.conv1.weight', 'gcns.3.blocks.2.conv1.loop_weight', 'gcns.3.blocks.2.conv1.bias', 'gcns.3.blocks.2.conv2.adj_mat', 'gcns.3.blocks.2.conv2.weight', 'gcns.3.blocks.2.conv2.loop_weight', 'gcns.3.blocks.2.conv2.bias', 'gcns.3.blocks.3.conv1.adj_mat', 'gcns.3.blocks.3.conv1.weight', 'gcns.3.blocks.3.conv1.loop_weight', 'gcns.3.blocks.3.conv1.bias', 'gcns.3.blocks.3.conv2.adj_mat', 'gcns.3.blocks.3.conv2.weight', 'gcns.3.blocks.3.conv2.loop_weight', 'gcns.3.blocks.3.conv2.bias', 'gcns.3.blocks.4.conv1.adj_mat', 'gcns.3.blocks.4.conv1.weight', 'gcns.3.blocks.4.conv1.loop_weight', 'gcns.3.blocks.4.conv1.bias', 'gcns.3.blocks.4.conv2.adj_mat', 'gcns.3.blocks.4.conv2.weight', 'gcns.3.blocks.4.conv2.loop_weight', 'gcns.3.blocks.4.conv2.bias', 'gcns.3.blocks.5.conv1.adj_mat', 'gcns.3.blocks.5.conv1.weight', 'gcns.3.blocks.5.conv1.loop_weight', 'gcns.3.blocks.5.conv1.bias', 'gcns.3.blocks.5.conv2.adj_mat', 'gcns.3.blocks.5.conv2.weight', 'gcns.3.blocks.5.conv2.loop_weight', 'gcns.3.blocks.5.conv2.bias', 'gcns.3.conv1.adj_mat', 'gcns.3.conv1.weight', 'gcns.3.conv1.loop_weight', 'gcns.3.conv1.bias', 'gcns.3.conv2.adj_mat', 'gconv.adj_mat'], unexpected_keys=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = modify_state_dict(checkpoint[\"model\"], params,get_bigmodule_list(model.named_children()), old_prefix=['gcns.2.conv2.weight','gcns.2.conv2.loop_weight','gcns.2.conv2.bias'], new_prefix=['gcns.3.conv2.weight','gcns.3.conv2.loop_weight','gcns.3.conv2.bias'])\n",
    "model.load_state_dict(state_dict,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_children at 0x7faa0127ff50>\n"
     ]
    }
   ],
   "source": [
    "print(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nn_encoder', 'gcns', 'unpooling', 'projection', 'gconv']\n"
     ]
    }
   ],
   "source": [
    "Bigmodule = []\n",
    "for name, module in model.named_children():\n",
    "    Bigmodule.append(name)\n",
    "print(Bigmodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "model_v1 = OrderedDict(model.named_children())\n",
    "    # remove avgpool,fc\n",
    "model_v1.pop(\"nn_encoder\")\n",
    "model_v1 = torch.nn.Sequential(model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcns\n",
      "unpooling\n",
      "projection\n",
      "gconv\n"
     ]
    }
   ],
   "source": [
    "for name, module in model_v1.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['gcns.0.blocks.0.conv1.adj_mat', 'gcns.0.blocks.0.conv1.weight', 'gcns.0.blocks.0.conv1.loop_weight', 'gcns.0.blocks.0.conv1.bias', 'gcns.0.blocks.0.conv2.adj_mat', 'gcns.0.blocks.0.conv2.weight', 'gcns.0.blocks.0.conv2.loop_weight', 'gcns.0.blocks.0.conv2.bias', 'gcns.0.blocks.1.conv1.adj_mat', 'gcns.0.blocks.1.conv1.weight', 'gcns.0.blocks.1.conv1.loop_weight', 'gcns.0.blocks.1.conv1.bias', 'gcns.0.blocks.1.conv2.adj_mat', 'gcns.0.blocks.1.conv2.weight', 'gcns.0.blocks.1.conv2.loop_weight', 'gcns.0.blocks.1.conv2.bias', 'gcns.0.blocks.2.conv1.adj_mat', 'gcns.0.blocks.2.conv1.weight', 'gcns.0.blocks.2.conv1.loop_weight', 'gcns.0.blocks.2.conv1.bias', 'gcns.0.blocks.2.conv2.adj_mat', 'gcns.0.blocks.2.conv2.weight', 'gcns.0.blocks.2.conv2.loop_weight', 'gcns.0.blocks.2.conv2.bias', 'gcns.0.blocks.3.conv1.adj_mat', 'gcns.0.blocks.3.conv1.weight', 'gcns.0.blocks.3.conv1.loop_weight', 'gcns.0.blocks.3.conv1.bias', 'gcns.0.blocks.3.conv2.adj_mat', 'gcns.0.blocks.3.conv2.weight', 'gcns.0.blocks.3.conv2.loop_weight', 'gcns.0.blocks.3.conv2.bias', 'gcns.0.blocks.4.conv1.adj_mat', 'gcns.0.blocks.4.conv1.weight', 'gcns.0.blocks.4.conv1.loop_weight', 'gcns.0.blocks.4.conv1.bias', 'gcns.0.blocks.4.conv2.adj_mat', 'gcns.0.blocks.4.conv2.weight', 'gcns.0.blocks.4.conv2.loop_weight', 'gcns.0.blocks.4.conv2.bias', 'gcns.0.blocks.5.conv1.adj_mat', 'gcns.0.blocks.5.conv1.weight', 'gcns.0.blocks.5.conv1.loop_weight', 'gcns.0.blocks.5.conv1.bias', 'gcns.0.blocks.5.conv2.adj_mat', 'gcns.0.blocks.5.conv2.weight', 'gcns.0.blocks.5.conv2.loop_weight', 'gcns.0.blocks.5.conv2.bias', 'gcns.0.conv1.adj_mat', 'gcns.0.conv1.weight', 'gcns.0.conv1.loop_weight', 'gcns.0.conv1.bias', 'gcns.0.conv2.adj_mat', 'gcns.0.conv2.weight', 'gcns.0.conv2.loop_weight', 'gcns.0.conv2.bias', 'gcns.1.blocks.0.conv1.adj_mat', 'gcns.1.blocks.0.conv1.weight', 'gcns.1.blocks.0.conv1.loop_weight', 'gcns.1.blocks.0.conv1.bias', 'gcns.1.blocks.0.conv2.adj_mat', 'gcns.1.blocks.0.conv2.weight', 'gcns.1.blocks.0.conv2.loop_weight', 'gcns.1.blocks.0.conv2.bias', 'gcns.1.blocks.1.conv1.adj_mat', 'gcns.1.blocks.1.conv1.weight', 'gcns.1.blocks.1.conv1.loop_weight', 'gcns.1.blocks.1.conv1.bias', 'gcns.1.blocks.1.conv2.adj_mat', 'gcns.1.blocks.1.conv2.weight', 'gcns.1.blocks.1.conv2.loop_weight', 'gcns.1.blocks.1.conv2.bias', 'gcns.1.blocks.2.conv1.adj_mat', 'gcns.1.blocks.2.conv1.weight', 'gcns.1.blocks.2.conv1.loop_weight', 'gcns.1.blocks.2.conv1.bias', 'gcns.1.blocks.2.conv2.adj_mat', 'gcns.1.blocks.2.conv2.weight', 'gcns.1.blocks.2.conv2.loop_weight', 'gcns.1.blocks.2.conv2.bias', 'gcns.1.blocks.3.conv1.adj_mat', 'gcns.1.blocks.3.conv1.weight', 'gcns.1.blocks.3.conv1.loop_weight', 'gcns.1.blocks.3.conv1.bias', 'gcns.1.blocks.3.conv2.adj_mat', 'gcns.1.blocks.3.conv2.weight', 'gcns.1.blocks.3.conv2.loop_weight', 'gcns.1.blocks.3.conv2.bias', 'gcns.1.blocks.4.conv1.adj_mat', 'gcns.1.blocks.4.conv1.weight', 'gcns.1.blocks.4.conv1.loop_weight', 'gcns.1.blocks.4.conv1.bias', 'gcns.1.blocks.4.conv2.adj_mat', 'gcns.1.blocks.4.conv2.weight', 'gcns.1.blocks.4.conv2.loop_weight', 'gcns.1.blocks.4.conv2.bias', 'gcns.1.blocks.5.conv1.adj_mat', 'gcns.1.blocks.5.conv1.weight', 'gcns.1.blocks.5.conv1.loop_weight', 'gcns.1.blocks.5.conv1.bias', 'gcns.1.blocks.5.conv2.adj_mat', 'gcns.1.blocks.5.conv2.weight', 'gcns.1.blocks.5.conv2.loop_weight', 'gcns.1.blocks.5.conv2.bias', 'gcns.1.conv1.adj_mat', 'gcns.1.conv1.weight', 'gcns.1.conv1.loop_weight', 'gcns.1.conv1.bias', 'gcns.1.conv2.adj_mat', 'gcns.1.conv2.weight', 'gcns.1.conv2.loop_weight', 'gcns.1.conv2.bias', 'gcns.2.blocks.0.conv1.adj_mat', 'gcns.2.blocks.0.conv1.weight', 'gcns.2.blocks.0.conv1.loop_weight', 'gcns.2.blocks.0.conv1.bias', 'gcns.2.blocks.0.conv2.adj_mat', 'gcns.2.blocks.0.conv2.weight', 'gcns.2.blocks.0.conv2.loop_weight', 'gcns.2.blocks.0.conv2.bias', 'gcns.2.blocks.1.conv1.adj_mat', 'gcns.2.blocks.1.conv1.weight', 'gcns.2.blocks.1.conv1.loop_weight', 'gcns.2.blocks.1.conv1.bias', 'gcns.2.blocks.1.conv2.adj_mat', 'gcns.2.blocks.1.conv2.weight', 'gcns.2.blocks.1.conv2.loop_weight', 'gcns.2.blocks.1.conv2.bias', 'gcns.2.blocks.2.conv1.adj_mat', 'gcns.2.blocks.2.conv1.weight', 'gcns.2.blocks.2.conv1.loop_weight', 'gcns.2.blocks.2.conv1.bias', 'gcns.2.blocks.2.conv2.adj_mat', 'gcns.2.blocks.2.conv2.weight', 'gcns.2.blocks.2.conv2.loop_weight', 'gcns.2.blocks.2.conv2.bias', 'gcns.2.blocks.3.conv1.adj_mat', 'gcns.2.blocks.3.conv1.weight', 'gcns.2.blocks.3.conv1.loop_weight', 'gcns.2.blocks.3.conv1.bias', 'gcns.2.blocks.3.conv2.adj_mat', 'gcns.2.blocks.3.conv2.weight', 'gcns.2.blocks.3.conv2.loop_weight', 'gcns.2.blocks.3.conv2.bias', 'gcns.2.blocks.4.conv1.adj_mat', 'gcns.2.blocks.4.conv1.weight', 'gcns.2.blocks.4.conv1.loop_weight', 'gcns.2.blocks.4.conv1.bias', 'gcns.2.blocks.4.conv2.adj_mat', 'gcns.2.blocks.4.conv2.weight', 'gcns.2.blocks.4.conv2.loop_weight', 'gcns.2.blocks.4.conv2.bias', 'gcns.2.blocks.5.conv1.adj_mat', 'gcns.2.blocks.5.conv1.weight', 'gcns.2.blocks.5.conv1.loop_weight', 'gcns.2.blocks.5.conv1.bias', 'gcns.2.blocks.5.conv2.adj_mat', 'gcns.2.blocks.5.conv2.weight', 'gcns.2.blocks.5.conv2.loop_weight', 'gcns.2.blocks.5.conv2.bias', 'gcns.2.conv1.adj_mat', 'gcns.2.conv1.weight', 'gcns.2.conv1.loop_weight', 'gcns.2.conv1.bias', 'gcns.2.conv2.adj_mat', 'gcns.2.conv2.weight', 'gcns.2.conv2.loop_weight', 'gcns.2.conv2.bias', 'gcns.3.blocks.0.conv1.adj_mat', 'gcns.3.blocks.0.conv1.weight', 'gcns.3.blocks.0.conv1.loop_weight', 'gcns.3.blocks.0.conv1.bias', 'gcns.3.blocks.0.conv2.adj_mat', 'gcns.3.blocks.0.conv2.weight', 'gcns.3.blocks.0.conv2.loop_weight', 'gcns.3.blocks.0.conv2.bias', 'gcns.3.blocks.1.conv1.adj_mat', 'gcns.3.blocks.1.conv1.weight', 'gcns.3.blocks.1.conv1.loop_weight', 'gcns.3.blocks.1.conv1.bias', 'gcns.3.blocks.1.conv2.adj_mat', 'gcns.3.blocks.1.conv2.weight', 'gcns.3.blocks.1.conv2.loop_weight', 'gcns.3.blocks.1.conv2.bias', 'gcns.3.blocks.2.conv1.adj_mat', 'gcns.3.blocks.2.conv1.weight', 'gcns.3.blocks.2.conv1.loop_weight', 'gcns.3.blocks.2.conv1.bias', 'gcns.3.blocks.2.conv2.adj_mat', 'gcns.3.blocks.2.conv2.weight', 'gcns.3.blocks.2.conv2.loop_weight', 'gcns.3.blocks.2.conv2.bias', 'gcns.3.blocks.3.conv1.adj_mat', 'gcns.3.blocks.3.conv1.weight', 'gcns.3.blocks.3.conv1.loop_weight', 'gcns.3.blocks.3.conv1.bias', 'gcns.3.blocks.3.conv2.adj_mat', 'gcns.3.blocks.3.conv2.weight', 'gcns.3.blocks.3.conv2.loop_weight', 'gcns.3.blocks.3.conv2.bias', 'gcns.3.blocks.4.conv1.adj_mat', 'gcns.3.blocks.4.conv1.weight', 'gcns.3.blocks.4.conv1.loop_weight', 'gcns.3.blocks.4.conv1.bias', 'gcns.3.blocks.4.conv2.adj_mat', 'gcns.3.blocks.4.conv2.weight', 'gcns.3.blocks.4.conv2.loop_weight', 'gcns.3.blocks.4.conv2.bias', 'gcns.3.blocks.5.conv1.adj_mat', 'gcns.3.blocks.5.conv1.weight', 'gcns.3.blocks.5.conv1.loop_weight', 'gcns.3.blocks.5.conv1.bias', 'gcns.3.blocks.5.conv2.adj_mat', 'gcns.3.blocks.5.conv2.weight', 'gcns.3.blocks.5.conv2.loop_weight', 'gcns.3.blocks.5.conv2.bias', 'gcns.3.conv1.adj_mat', 'gcns.3.conv1.weight', 'gcns.3.conv1.loop_weight', 'gcns.3.conv1.bias', 'gcns.3.conv2.adj_mat', 'gcns.3.conv2.weight', 'gcns.3.conv2.loop_weight', 'gcns.3.conv2.bias', 'gconv.adj_mat', 'gconv.weight', 'gconv.loop_weight', 'gconv.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "sparse tensors do not have storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13410/4229602121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_v1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/3dproject/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/3dproject/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/3dproject/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/3dproject/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/3dproject/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__reduce_ex__\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# See Note [Don't serialize hooks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_has_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         args = (self.storage(),\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: sparse tensors do not have storage"
     ]
    }
   ],
   "source": [
    "torch.save(model_v1.state_dict(), 'model_v1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cb8d57a847f16fc8404e2dd8b83ca051b33377fcac5c0d474ea003e899540fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
